# Interview Analysis: Mohamed Cassim
**Date:** 2026_01_20 09_28 SAST
**Source:** OMT Discovery Interview with StrideShift (Mohamed Cassim) – 2026_01_20 09_28 SAST – Notes by Gemini.docx
**Transcript word count:** 8516
**Analysis model:** claude-haiku-4-5

# OMT Discovery Interview Analysis: Mohamed Cassim

## 1. Interviewee Role & Background

**Role in OMT Review Process:**
Mohamed serves as an adjudicator for OMT, specifically reviewing applications in the "financial applications" category, though he notes he feels somewhat "pigeonholed" into this area despite his broader expertise.

**Duration of Involvement:**
The transcript does not specify how long Mohamed has been adjudicating for OMT, though he mentions a relationship with Tracy (OMT leadership) through a fellows network.

**Discipline/Expertise Area:**
Mohamed has exceptionally diverse experience across multiple sectors:
- **Public Sector**: Built financial data warehouse for post-1994 South Africa; architected jobs fund for national treasury; ran NSF funding programs
- **Private Sector Development**: Co-founded mergers & acquisition shop; invested in mobile wallet company (now operates across 43 countries, serves millions)
- **Social Enterprise**: Ran KFC franchise operations in Eastern Cape creating ~50 stores and substantial employment
- **Current Role**: Co-founder of Africa Climate Ventures (climate-tech investment fund, $10M+ raised)
- **Academic Background**: Pharmacy undergraduate, MBA, studied strategy and innovation at Oxford (2013-14)
- **Personal Orientation**: Strategy, innovation, development economics, job creation across African contexts

---

## 2. Current Review Process Description

**Process Overview:**
Mohamed describes a thorough, methodical approach that is "longish" and "old school."

**Specific Steps:**

1. **Complete Document Review**: Reads all submission documents in full, typically over several nights while family sleeps (Mohamed identifies as a night owl)

2. **Two-Stage Assessment Framework**:
   - **Stage 1 - Merit Assessment**: Evaluates submission "on its own merit" as a standalone case
   - **Stage 2 - Calibration via Relativity**: When similar applications exist, uses comparative analysis to differentiate between candidates and provide nuanced perspective

3. **Initial Depth Assessment**: Uses extensive sector experience to quickly determine submission depth—can "fairly quickly" distinguish between "blustering" and actual achievement

4. **Institutional Performance Review**: For candidates with substantial experience (postgrad + 10+ years), examines performance of institutions where they worked, particularly in relation to their stated functions

5. **Logic and Intention Analysis**: Examines how candidates think and construct arguments, particularly distinguishing between genuine thesis focus versus funding-seeking as a bridge to other goals

6. **Reference Letter Evaluation**: Uses reference letters as indicators of authenticity and motivation, valuing "heartfelt proper letters from mentors or professors" and detecting AI-generated or candidate-drafted letters

7. **Rubric Application with Subjective Commentary**: Adheres to rubric while adding subjective judgment, particularly in areas like budget assessment and "skin in the game" evaluation

8. **Relative Differentiation**: When scoring similar candidates, provides explicit comparative notes explaining differences in sector exposure, potential impact, or career intentions rather than simply scoring one higher than another

**Tools/Systems Currently Used:**
- OMT's adjudication guide/rubric
- Reference letters and application documents
- Professional judgment drawing on sector knowledge
- Recently purchased AI tool for exploratory use (appears to be Claude or similar)

**Time Spent:**
- Several nights of full document reading per adjudication cycle
- Unclear per-application time, but clearly substantial given depth of analysis described

---

## 3. Pain Points & Challenges

**Frustrations with Current System:**

1. **Pigeonholing into Financial Applications**: 
   - Mohamed feels confined to "financial applications" despite broader expertise across public sector, development, climate ventures
   - Notes this "left a little bit of value on the table"
   - Has never raised this concern vocally, indicating potential organizational communication barriers

2. **Rubric Limitations**:
   - **"Extraordinary Talent" Category Too Blunt**: "I feel leaves a little bit too much room for adjudicators...I don't even know how you decide what talent is...I think it's a little bit blunt"
   - Lacks scientific definition, leading to inconsistency
   - Conflates different types of talent (probability of amazing output vs. capability to deliver on high-value topics)

3. **Bias Toward Non-SA Specialization**:
   - Rubric implicitly devalues specializations "available in SA"
   - Misses areas where South Africa excels (e.g., mining, extractive industries)
   - Creates bias against candidates repatriating intellectual property to SA

4. **"Intended Study" Category Subjectivity**:
   - Heavily relies on adjudicator's broad experience
   - Difficult to calibrate across different reviewers with different expertise

5. **Personal Motivation Assessment Challenges**:
   - Current focus on motivation letters is flawed—"a letter you can get a good friend to write...you can get AI to write it for you"
   - Requires deep reading of full application history, creating cognitive load

6. **Reference Letter Verification**:
   - Must distinguish between genuine letters and candidate-drafted letters signed by busy referees
   - Time-consuming manual verification of authenticity

7. **Institutional Performance Research**:
   - Requires manual checking of institutional performance against candidates' claimed experience
   - Must verify financial statements and sector performance to validate CV claims
   - "It's a pile of work. It's a pile of work."

8. **Probability vs. Intent Confusion**:
   - Difficulty assessing probability of delivery vs. merit of intent
   - Must consider candidate's life circumstances (dependents, financial stress) that affect delivery capability
   - No systematic framework for holistic capability assessment

9. **Unclear Value Contribution**:
   - Uncertain whether detailed comparative notes are actually useful to OMT decision-makers
   - Describes providing "explicit thought to whoever the recipient is" but doesn't know if recipients value this depth
   - Questions if the effort is "worth their while"

10. **National Education System Context**:
    - Must factor in South Africa's low NSF throughput (1 degree for every 5 students funded)
    - Creates systemic barriers to probability of delivery that are beyond individual adjudicator control

**Specific Bottlenecks:**
- Manual verification of institutional performance and financial statements
- Distinguishing genuine reference letters from AI-generated or candidate-drafted letters
- Assessing psychological fit (psychographic analysis) between candidate and topic requirements
- Cross-checking CV claims against institutional performance data
- Calibrating subjective categories across multiple adjudicators with different expertise

---

## 4. What They Value in Applications

**Key Criteria Mohamed Prioritizes:**

1. **Probability of Delivery Over Intent**:
   - "It's not quite simply about the merit of the intent...everybody can write a brilliant piece of intent. It's also about the probability of that being delivered"
   - Draws from investment world perspective: "either it is probable or it's not"
   - Looks for realistic assessment of candidate's capacity to complete work

2. **"Skin in the Game"**:
   - Strong believer that financial investment by candidate signals commitment
   - Will comment if candidate hasn't invested own cash (when they have capacity to do so)
   - Recognizes constraints: won't penalize those supporting family members

3. **Authentic Achievement Evidence**:
   - Can distinguish between "blustering" and actual accomplishment
   - Values demonstrated impact through institutional context (e.g., did the organization perform well during candidate's tenure?)
   - Looks at functions held: "if they're in some kind of position of leadership," checks if that area performed well

4. **Alignment Between Candidate Profile and Topic Requirements**:
   - Assesses whether candidate's temperament/experience matches project needs
   - Example: topic might require "an extrovert of this kind with that type of experience"
   - Uses psychographic analysis to match person to project

5. **Genuine, Heartfelt Reference Letters**:
   - Values letters that feel authentic and come from different angles
   - Looks for letters from "mentors or professors" that demonstrate real knowledge of candidate
   - Uses reference letters to validate motivation beyond written statements
   - Detects candidate-drafted letters (can tell by authenticity markers)

6. **Depth of Intended Study**:
   - Values candidates with genuine intellectual curiosity
   - Looks for those pursuing study for its own merit, not as funding bridge
   - Can detect candidates "just collecting funds" to "spend a couple years filling up time"
   - Examines how candidates construct their logic and reasoning

7. **Sector Specialization with Repatriation Potential**:
   - Values specializations that can be brought back to benefit SA
   - Example: mining expertise can create technology, associated industries, economic development
   - Pushes back against rubric bias toward unavailable specializations

8. **Holistic Life Context**:
   - Considers dependents, family obligations, financial stress
   - Recognizes this context affects delivery probability
   - Suggests additional funding if necessary to ensure focus on academic work
   - Views as investment decision: "if this particular piece of study holds that much merit then I do want to make sure that the probability of being delivered is high"

9. **Clear Logic and Reasoning**:
   - Values how candidates present arguments and construct ideas
   - Looks for clarity in communication and thinking
   - Distinguishes between confused thinking and language barriers

10. **Institutional Track Record**:
    - For senior candidates, examines institution performance during their employment
    - Validates achievements by checking if organization performed well in stated areas
    - Won't recommend someone from organization that failed in their stated domain

**Red Flags Mohamed Watches For:**

1. **Lack of Financial Commitment**: Candidate hasn't invested own resources when capable
2. **Inconsistency Between Claims and Reality**: CV claims don't align with institutional performance during candidate's tenure
3. **Generic Reference Letters**: Letters that appear candidate-drafted or AI-generated
4. **Funding as Bridge Strategy**: Candidate seeking funds primarily to "fill time" rather than genuine research
5. **Mismatch Between Profile and Topic**: Psychographic misalignment (e.g., introverted candidate for project requiring extroversion)
6. **Overcommitted Candidates**: Those with excessive dependents/obligations that will interfere with delivery
7. **Unclear Logic**: Poorly constructed arguments suggesting unclear thinking

**What Makes Applications Stand Out:**

1. **Authentic Passion with Realistic Planning**: Genuine motivation combined with practical assessment of delivery capability
2. **Demonstrated Impact**: Track record showing not just credentials but actual achievement in relevant areas
3. **Diversity in Perspective**: Different sector exposure, international experience, or unique angle on problem
4. **Investment of Self**: Financial, time, or emotional investment showing genuine commitment
5. **Clear Future Vision**: Specific, thoughtful articulation of how study will enable impact
6. **Institutional Validation**: Strong reference letters that provide independent verification of capability and motivation

**How Mohamed Weighs Different Factors:**

Using investment portfolio logic—multifaceted considerations:
- Probability of delivery weighted heavily (not just merit of intent)
- Life circumstances factored into funding recommendations
- Sector impact and repatriation potential considered
- Institutional validation weighted significantly
- Comparative advantage over similar candidates highlighted
- Holistic assessment rather than isolated rubric scores

---

## 5. Views on AI/Technology

**Overall Attitude Toward AI in Review Process:**

Mohamed is cautiously optimistic but deeply cautious about limitations. He sees AI as potentially valuable for specific tasks but fundamentally limited for assessment of future capability.

**Specific Hopes for AI:**

1. **Efficiency Gains on Binary Tasks**: 
   - "Could be helpful if the binary stuff...could answer that in about 30 seconds and the adjudicator can decide"
   - Example: Budget questions are "straightforward and simple" and could be automated

2. **Topic Commonality Assessment**:
   - "AI could help determine if a topic is uncommon amongst academic institutions by trolling databases"
   - Could scrape academic databases to position candidate's research in landscape

3. **Psychographic Matching**:
   - "From the cognitive perspective, it would be fantastic if it said the topic requires an extrovert of this kind with that type of experience and this guy doesn't have it"
   - Could conduct profile analysis against topic requirements

4. **Institutional Performance Verification**:
   - "I would love for it to tell me that from this guy's CV I checked on the institutions...I brought back the following financial statements"
   - Could verify CV claims against institutional records
   - Could check company/organization performance during candidate's tenure

5. **Reference Letter Authentication**:
   - "I'd like you to tell me that AI wrote the reference letters up front, right? So that I didn't have to think about that"
   - Could detect AI-generated or candidate-drafted letters

6. **Reducing Superfluous Cognitive Load**:
   - AI as "cognitive assistant to handle binary tasks and reduce superfluous cognitive load"
   - Would free adjudicators to focus on "deep dive reasoning on specific issues rather than initial fact-finding"

**Fundamental Concerns About AI:**

1. **Cannot Assess Future Probability of Delivery**:
   - **Central Concern**: "I don't think what it can do is tell the probability of somebody delivering on something"
   - "AI is built on data that is in the internet...by its very nature AI would go on historic trends when all of us sitting at this table know that the future is not told by history alone. It's told by capability for tomorrow"
   - AI "is awfully equipped for that. It's just incapable to be frank"

2. **Bias Toward Historical Patterns**:
   - "AI is poorly equipped to determine the probability of somebody delivering on something"
   - Creates "bias toward solving yesterday's problems"
   - Violates fundamental principle: "even as adjudicators have to be careful about having a bias to solving yesterday's problems"

3. **Cannot Make Capability Judgments**:
   - Cannot assess whether candidate has genuine capability vs. just credentials
   - Cannot assess life circumstances' impact on delivery probability
   - Cannot evaluate quality of thinking or authentic motivation

**What Mohamed Would/Wouldn't Want Automated:**

**Would Automate (Binary/Factual):**
- Budget verification (amounts, previous funding, own investment, timeline)
- Topic commonality research across academic institutions
- Reference letter authenticity detection
- Institutional performance verification
- Basic CV validation against institutional records
- Financial statement analysis for referenced organizations

**Would NOT Automate (Judgment/Future-Oriented):**
- Probability of delivery assessment
- Capability evaluation
- Authentic motivation assessment
- Psychographic matching (though AI could assist by flagging potential mismatches)
- Relative merit between similar candidates
- Future impact potential
- Assessment of thinking quality or logic

**Trust and Transparency Requirements:**

1. **Transparency About AI Limitations**:
   - Must be clear about what AI is and isn't doing
   - Cannot position AI as assessing delivery probability or capability
   - Should be explicit about historical data bias

2. **Verification Requirement**:
   - AI findings should be verifiable by human adjudicator
   - Adjudicator must be able to check AI's institutional performance claims
   - Reference letter detection should be explainable

3. **Responsibility for Judgments**:
   - Adjudicator remains responsible for final assessment
   - AI assists with fact-finding, not judgment-making
   - Preserves adjudicator's professional accountability

4. **Honest Labeling**:
   - "I bought this tool set recently...I said to it the other day, write me a legal letter"
   - Appreciates AI for what it can do; wants clear boundaries on what it cannot

---

## 6. Suggestions & Ideas

**Improvements to Rubric:**

1. **Redefine "Extraordinary Talent" Category**:
   - Make definition "more scientific"
   - Clarify what talent means: "Are we talking about the probability that if this guy wrote some piece over a period of time and was funded, he'd do something amazing and the world would see it? Or talking about the probability of him taking a high high value topic and delivering it to the extent that the world can build on it?"
   - Reduce subjectivity and improve consistency across adjudicators

2. **Revise "Specialization Unavailable in SA" Bias**:
   - Recognize areas where SA excels (mining, extractive industries)
   - Value repatriation of intellectual property to SA
   - Create technology and associated industries from SA expertise
   - Remove implicit bias toward foreign specializations

3. **Improve "Personal Motivation" Assessment**:
   - De-emphasize written motivation letters (easily AI-generated)
   - Rely more on demonstrated history and actions
   - Use reference letters as authenticity indicators
   - Assess motivation through pattern of choices, not assertions

4. **Clarify "Intended Study" Category**:
   - Acknowledge need for adjudicator's broad experience
   - Provide examples of what constitutes significant vs. trivial study
   - Support adjudicators in applying spectrum experience

**Features/Capabilities for New System:**

1. **Cognitive Load Reduction Assistant**:
   - AI module that handles institutional performance verification
   - Automatically retrieves financial statements for referenced organizations
   - Flags consistency issues between CV claims and institutional reality
   - Reports: "this guy's not very honest about his achievements because those companies didn't do so well for the following reasons"

2. **Reference Letter Authentication Tool**:
   - Flags AI-generated or candidate-drafted reference letters up front
   - Allows adjudicator to focus on authentic