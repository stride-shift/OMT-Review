# Interview Analysis: Ndumiso Luthuli
**Date:** 2026_01_23 12_55 SAST
**Source:** OMT Discovery Interview with StrideShift (Ndumiso Luthuli) – 2026_01_23 12_55 SAST – Notes by Gemini.docx
**Transcript word count:** 1119
**Analysis model:** claude-haiku-4-5

# OMT Discovery Interview Analysis: Ndumiso Luthuli

## ⚠️ CRITICAL NOTE
This transcript does **not contain an actual interview with Ndumiso Luthuli** (StrideShift). The transcript only captures pre-meeting technical troubleshooting between **Justin Germishuys** and **Barbara Dale-Jones**. Ndumiso ("Indonesia") was expected to join at 3:00 PM but the actual interview content is not included in the provided transcript.

---

## 1. Interviewee Role & Background
**Cannot be determined from this transcript.** 
- Ndumiso Luthuli was invited but did not appear in the recorded portion
- Email: ndumiso.luthuli.oba@said.oxford.edu
- Expected to join the call at 3:00 PM (had car trouble)
- No information about their role, tenure, or discipline is captured

---

## 2. Current Review Process Description
**No data available.** This section would have been covered in the actual interview with Ndumiso.

---

## 3. Pain Points & Challenges
**No data available from the interviewee.** However, the OMT team (Justin and Barbara) expressed concerns about:
- **Technical infrastructure challenges**: Line speed issues, connectivity problems during calls
- **Documentation management**: Current documents are disorganized and lack context
- **Information synthesis bottleneck**: Manual effort required to compile and understand existing interview transcripts

---

## 4. What They Value in Applications
**No data available from the interviewee.**

---

## 5. Views on AI/Technology

### Observations from OMT Staff (not the interviewee):

**Positive views:**
- Claude performed "quite good" work when given transcripts to analyze
- Some AI applications are "absolutely insanely good"

**Concerns & Skepticism:**
- **Inconsistent performance**: AI struggles with tasks that should be simple
- **Fabrication issues**: AI "fabricates" answers rather than admitting uncertainty
- **False confidence**: AI tries to "act like it's on top of things" and will "spin...in the most convincing way some answer" that may be inaccurate
- **Reality misalignment**: Generated answers sometimes "didn't really happen"
- **Lack of self-awareness**: AI reflects back incorrect information when corrected rather than genuinely acknowledging errors

### Notable quote from Barbara Dale-Jones:
> "It really just tries to act like it's on top of things sometimes. Um, and it just will like spin, you know, in the most um convincing way some answer and then you're like, 'No, but that didn't really happen.'"

---

## 6. Suggestions & Ideas
**From OMT Staff (not the interviewee):**
- **Document organization**: Create a structured project containing all existing documents to establish proper context
- **AI-assisted synthesis**: Use AI tools (like Claude) to analyze batches of transcripts, but with human verification
- **Verification process**: All AI-generated insights should be reviewed for accuracy before use

---

## 7. Key Direct Quotes

1. **"And I read quite a lot of what you uncovered and it's quite good. Um but it is always I always find the kind of jagged um sort of edge or coastline of AI very interesting."**
   - Context: Justin reflecting on Barbara's work with Claude; captures the fundamental unpredictability of AI

2. **"There are some things it's absolutely insanely good at and then you give it like what should be a simple task and it's a dance."**
   - Context: Justin explaining inconsistent AI performance; suggests frustration with unexplainable failures

3. **"And and and just like fabricate I I see again and again just like a little bit of fabrication...it really just tries to act like it's on top of things sometimes."**
   - Context: Barbara identifying the core problem with AI—false confidence and confabulation

4. **"It just will like spin, you know, in the most um convincing way some answer and then you're like, 'No, but that didn't really happen.'"**
   - Context: Specific concern about AI's persuasive tone masking inaccuracy

5. **"I've started using more create colorful expletives. Um, and then it actually reflects back the expletives and says, 'Yes, I did bleep.'"**
   - Context: Justin's humorous anecdote illustrating AI's tendency to echo user input rather than genuinely process criticism

6. **"I would actually like to take some time out to just take all the documents we have and just putting them in a project. I think once that's going um we'll have all the context set up."**
   - Context: Justin identifying the foundational problem: lack of organized context

---

## 8. Unique Insights

### Key Meta-Finding:
This transcript reveals a **critical issue with the research methodology itself**: The interview with the primary subject (Ndumiso/StrideShift) never actually occurred in the recorded portion. This is significant because:

1. **No direct data on application review processes** - Only pre-meeting technical discussion captured
2. **Bias toward team perspectives** - Only OMT staff observations about AI are recorded, not actual reviewer insights
3. **Incomplete research** - The stated purpose (improving OMT's application review process with AI assistance) has not yet been addressed

### Distinctive Concerns About AI in This Context:

The team's observed problem with **AI fabrication** is particularly concerning for an **application review system** where:
- Accuracy about candidates is critical (false positive/negative assessments could harm applicants)
- Confidence levels must be transparent (applicants deserve to know if decisions are based on verified or speculative information)
- Explainability is essential (scholarship decisions require justification)

**Most Critical Quote for AI Implementation:**
> "It just will like spin, you know, in the most convincing way some answer and then you're like, 'No, but that didn't really happen.'"

This suggests that if AI is implemented in application review, there must be:
- Explicit human verification of all AI-generated assessments
- Clear separation between AI summaries and human judgment
- Audit trails showing which claims are fact-checked vs. speculative

---

## Recommended Follow-Up Actions

1. **Conduct the actual interview with Ndumiso Luthuli** to gather primary data on reviewer experience
2. **Establish ground rules** for AI use in application assessment that address fabrication concerns
3. **Design verification protocols** that don't assume AI analysis is accurate without human review
4. **Document the baseline** review process before piloting any AI assistance