# Interview Analysis: Philippe Burger
**Date:** 2026_01_13 13_58 SAST
**Source:** OMT Discovery Interview with StrideShift (Philippe Burger) – 2026_01_13 13_58 SAST – Notes by Gemini.docx
**Transcript word count:** 5639
**Analysis model:** claude-haiku-4-5

# OMT Discovery Interview Analysis: Philippe Burger

## 1. Interviewee Role & Background

**Role:** Adjudicator for the Oppenheimer Memorial Trust scholarship review process

**Duration of Involvement:** 2-3 years

**Discipline/Expertise:** Economist and macroeconomist; reviews applications in the broader business management and economics field

**Application Levels Reviewed:** Masters, PhD, and Scholar (postgraduate) applicants

---

## 2. Current Review Process Description

### Process Flow:
1. **Initial Classification:** Applications organized by degree level (Masters, PhD, Scholar) and category
2. **Academic Record Review:** First filter examines applicants' academic performance
3. **Motivation Essay Assessment:** Reviews written motivation/motivation essay for clarity, focus, realism, and ambition
4. **Field Alignment Check:** Verifies intended field of study aligns with existing qualifications and disciplinary foundation
5. **Scoring:** Assigns numerical scores on a scale of 5, using 3 as average baseline
6. **Iterative Ranking:** Creates provisional ranking that is adjusted as more candidates are reviewed; revisits rankings after reviewing 5-6 candidates to establish relative positions
7. **Benchmarking:** Reads through 10-12 applications before settling on final scores to establish relative benchmarking context

### Tools/Systems:
- Written motivation essays as primary assessment documents
- Numerical scoring system (scale of 5, with 3 as average)
- No mention of formal scoring rubric or structured evaluation framework
- No formal bias mitigation tools currently in place
- Use of Turnitin's AI detector mentioned for parallel university process (not currently used for OMT)

### Time Considerations:
- Annual process conducted "from scratch" each year due to 12-month gap between cycles
- Estimates that stricter pre-screening could save time by eliminating clearly unqualified applicants earlier
- No specific time estimates provided for individual application reviews

---

## 3. Pain Points & Challenges

### Primary Frustrations:

**AI-Generated Content Detection:**
- Strong suspicion that some motivation essays are written by AI, evidenced by sudden improvements in English quality
- Difficulty distinguishing genuine applicant voice from AI-generated content as models become more sophisticated
- Increasing problem anticipated as text generation technology advances

**Subjectivity in Scoring:**
- Translation from subjective impression to numerical score always contains subjective elements
- Difficulty quantifying what makes an application move from average (3) to above-average (4-5)
- Challenge in identifying the "extra little something" that distinguishes borderline cases

**High Application Volume with Complex Cases:**
- Majority of applications are Masters and PhD level, which are "more complicated to deal with" than Scholar applications
- Competition is stiff; only top few applicants pass initial academic filter
- Must manage large cohorts while making nuanced judgments

**Borderline/Edge Cases:**
- Difficulty making definitive yes/no decisions on borderline applications
- Ambiguity in assessing whether applicant demonstrates genuine ambition vs. generic motivation statements
- Challenge distinguishing thoughtful motivation from superficial "I want to change the world" statements

**Alignment Assessment Issues:**
- Interdisciplinary applicants sometimes lack foundational disciplinary knowledge for proposed topics
- Difficulty identifying gaps between intended study and academic preparation, particularly in quantitatively demanding fields
- Weakness of South African university preparation in quantitative disciplines creates additional assessment burden

**Benchmarking Challenges:**
- Annual "reset" means context from previous years must be reconstructed after reviewing first few applications
- Tension between relative benchmarking (comparing within current cohort) and absolute benchmarking (comparing against international standards)
- Risk of ranking applicants highly within cohort while they still fall short of absolute standards for their intended programs

**Inefficient Pre-Screening:**
- Currently processes applications that lack sufficient academic credentials for their intended elite international universities
- Time wasted on clearly unqualified applicants who consume reviewer time without realistic chance of success

---

## 4. What They Value in Applications

### Key Assessment Criteria:

**Academic Record (Primary Filter):**
- Strong academic performance is first and most rigorous filter
- Marks must align with demands of intended institution and program
- Example given: 78% average insufficient for top international universities

**Field Alignment:**
- Applicant's intended field of study must align with existing qualifications
- Academic background must provide sufficient disciplinary foundation for proposed topic
- Quantitative capability must match program demands (e.g., accounting requires stronger quantitative skills than marketing or HR)

**Motivation Essay Quality (Secondary Differentiation):**
- **Focus:** Clear articulation of what applicant wants to study
- **Realism:** Feasibility of proposed research/study direction
- **Clarity:** Transparent communication of goals
- **Authenticity:** Genuine voice and authorship (increasingly difficult to assess)
- **Ambition:** Evidence of drive beyond generic statements like "I want to change the world"
- **Thoughtfulness:** Demonstration that applicant has genuinely considered their motivation
- **Flare/Drive:** Personal qualities that distinguish exceptional essays from mediocre ones

**Value Added:**
- What specific value does the applicant bring to their field of study?
- Is the application showing genuine specialization or generic qualification-seeking?

**Disciplinary Foundation:**
- For PhD applicants: mastery of field literature and existing knowledge base
- For Masters applicants: basic foundational skills and understanding
- For Scholars: highest standard—requires excellence even to achieve average score

**Contextual Background Understanding:**
- For South African applicants: recognition of educational disparities across socioeconomic backgrounds
- Applicants from non-private school backgrounds may have less sophisticated language or grammar without diminished intellectual capacity

### Red Flags:

1. **AI-Generated Essays:** Sudden improvement in English quality, bland and generalist language, absence of personal voice, lack of ambition or distinctive insight

2. **Academic Insufficiency:** Marks too low for intended program demands; inadequate preparation in quantitative skills for quantitatively demanding programs

3. **Misalignment:** Interdisciplinary moves without foundational knowledge; proposed research not grounded in existing academic preparation

4. **Generic Motivation:** Boilerplate statements ("I am motivated," "I want to change the world") without evidence of genuine thought or specific focus

5. **Lack of Disciplinary Knowledge:** For PhD applicants, unfamiliarity with field literature or limited understanding of existing knowledge base

6. **Insufficient Depth:** Essay demonstrates surface-level thinking rather than genuine engagement with intended field

### What Makes Applications Stand Out:

1. **Distinctive Ambition:** Clear evidence of drive and thoughtful motivation beyond generic aspirations
2. **Authentic Voice:** Personal, genuine communication that reveals applicant's genuine thinking
3. **Specific Focus:** Clearly articulated, specific research interests rather than broad field interest
4. **Demonstrated Fit:** Clear alignment between academic background and intended program; evidence of requisite foundational knowledge
5. **Realistic Assessment:** Applicant demonstrates understanding of what their chosen field demands
6. **Evidence of Thought:** Essay shows genuine intellectual engagement with proposed research direction

### Weighting of Factors:

1. **Academic Record:** Primary filter; most heavily weighted initially
2. **Field Alignment:** Secondary filter; eliminates candidates with insufficient disciplinary foundation
3. **Motivation Essay:** Tertiary differentiation; determines who among academically qualified applicants rises above average
4. **Level-Specific Demands:** Weightings adjusted by application level
   - **Masters:** Basic foundational skills sufficient
   - **PhD:** High standards for mastery of field and literature
   - **Scholar:** Highest standards; must demonstrate excellence to achieve even average score

---

## 5. Views on AI/Technology

### Overall Attitude:
Pragmatic concern. Philippe acknowledges AI as an inevitable and escalating challenge but does not express ideological opposition. His tone is realistic about the problem and solution-oriented.

### Specific Concerns:

**Detection Problem:**
- Current AI detection is difficult; approximately 80% of essays in one parallel university process flagged by Turnitin's AI detector at high probability
- Increasing sophistication of generative models makes detection harder and will continue deteriorating
- Cannot definitively prove AI authorship even with detection tools

**Capability Escalation:**
- Generative text was "bland and generalist" in 2023-2024, allowing distinguishing features (ambition, flare, drive, focus) to be identifiable
- Current and future models can be prompted to generate essays reflecting sophistication, ambition, and field-specific knowledge
- Problem will become "more and more difficult" as technology advances

**Impact on Essay Validity:**
- Essays will become unreliable as distinguishing mechanism between applicants in foreseeable future
- "Going forward I think that you're going to have a serious problem relying on essays as a mechanism for distinguishing between applicants"

### What Would Be Automated (Acceptable to Philippe):

1. **Pre-Screening:** Stricter automated or systematic pre-screening to filter candidates whose academic records clearly insufficient for intended programs

2. **Relative Benchmarking Calculations:** Computational support for establishing relative rankings within cohorts

3. **Administrative Tasks:** Candidate data organization, scoring sheet management, etc.

### What Should NOT Be Automated (According to Philippe):

1. **Final Judgments on Borderline Cases:** Assessment of the "extra little something" that moves candidates from average to above-average requires human judgment and tacit knowledge

2. **Holistic Academic Fit Assessment:** Determination of alignment between applicant background and intended field requires contextual understanding that humans provide better

3. **Bias-Conscious Evaluation:** Assessment that accounts for socioeconomic background diversity and educational disparity context requires human sensitivity

### Trust and Transparency Requirements:

**Interviews as Verification Mechanism:**
- Uses interviews as comparison point with essay content to detect discrepancies
- "It's you and the interview panel. It's not you and ChatGPT"
- Interview allows verification of whether applicant actually wrote/understands essay content

**Benchmarking Transparency:**
- Needs absolute standards in addition to relative ones
- Wants assurance that top-ranked applicants in cohort will actually succeed at intended programs (not just rank well relative to peers)
- Requires clear communication of standards and their justification

**Human-in-the-Loop Philosophy:**
- AI should support human judgment, not replace it
- Critical decisions need human oversight and contextual understanding

---

## 6. Suggestions & Ideas

### Process Improvements:

**Address AI Challenge:**

1. **Implement Interviews:**
   - Use interviews as direct verification mechanism for essay authenticity
   - Compare essay content against in-person responses to verify applicant understanding
   - "Interview panel. It's not you and ChatGPT"

2. **Timed, Proctored Essays:**
   - Require essays written in real-time (e.g., "log on at 9:00 and have 25 minutes")
   - Implement proctoring to ensure applicant authorship
   - Parallels university oral defense model now used to verify thesis authorship

### Stricter Pre-Screening:

1. **Earlier Academic Filter:**
   - Screen out applicants whose academic records clearly insufficient for intended high-level international universities
   - Example: Applicant with 78% average seeking admission to top-tier international program should be filtered pre-review
   - Save adjudicator time by eliminating clearly unqualified candidates

2. **Quantitative Preparedness Assessment:**
   - For programs with high quantitative demands (accounting, econometrics, etc.), pre-screen for adequate quantitative foundation
   - South African universities weak in quantitative preparation; flag candidates with only first/second-year statistics modules applying to highly quantitative programs
   - Earlier elimination of misaligned candidates

3. **Strengthen Pre-Screening Rigor:**
   - "I think there is a pre-screening, but it could be a bit a bit stricter"

### Bias Mitigation:

1. **Conscious Awareness Framework:**
   - Review process should explicitly account for socioeconomic background diversity
   - Avoid penalizing applicants from non-private school backgrounds for less sophisticated language or grammar
   - Recognize legitimate intellectual capability despite language sophistication differences

2. **Importance of Personal Essay:**
   - Personal essays critical for understanding applicant background and context, particularly in diverse country context
   - Should inform interpretation of language quality and expression sophistication

### Benchmarking Framework:

1. **Dual Benchmarking Approach:**
   - Maintain both relative benchmarking (within cohort) and absolute benchmarking (against program/institutional demands)
   - Ensure top-ranked applicants meet absolute standards for their intended programs, not just rank highest in cohort
   - "You're number one in our pack of 20 but then they will still fall short of what is needed"

2. **Context-Specific Absolute Standards:**
   - Different programs require different quantitative/qualitative capability baselines
   - Accounting more quantitatively demanding than marketing or HR
   - Align assessment standards to specific program requirements

### Rubric Enhancement:

Philippe did not propose specific rubric changes but implied that current system lacks:
- Explicit, transparent criteria for distinguishing between adjacent scores (3 to 4, 4 to 5)
- Articulated markers for "the extra little something"
- Formalized guidance on level-specific weighting differences

---

## 7. Key Direct Quotes

### On Subjectivity in Essays and Judgment:

**Quote 1:**
> "So so so it's usually with when when you start reading the the the the the essay uh because that is you know it's like grading essays...when when it is more about the self-escription essay or or later on when you look at what what the motivation for what they want to study um there's a bit more to that uh but but when it's this motivation essay I think that is where the the biggest issue comes in and that that is very subjective"

*Context: Philippe identifying where judgment calls and gut feel most heavily influence scoring, specifically locating the challenge in motivation essay assessment*

---

**Quote 2:**
> "There's there's always uh in that because you you do a translation of what your impression into a into a score. Um so so there will always be something uh uh um in there that that's a bit subjective."

*Context: Explaining why scoring inherently contains subjective elements despite efforts to standardize, highlighting the translation from impression to number*

---

### On Identifying Borderline Cases:

**Quote 3:**
> "So as I said then then you look at let's say the essay or the motivation for what they want to go study and you look um and and and if it is a borderline um you know you look for for for that little extra that that that would carry it to the from a three to a four or four to a five. Um uh uh so so that is usually you know what's the value added that that that you bring"

*Context: Describing the process for distinguishing between average and above-average applications, using the metaphor of "that little extra"*

---

**Quote 4:**
> "Can you can you spot a bit of ambition or is this just, you know, a run-of-the-mill I'm going to change the world? Uh, has there's been some thought in it? I think that's the other thing you you you know, you can get you can write something very easily to say yes, I want to change this and that, but has there some been some thought in in in in in that motivates you to to to do this?"

*Context: Explaining what he looks for to elevate applications from generic to distinguished; identifying "thoughtfulness" as a key differentiator*

---

### On AI and Essay Assessment:

**Quote 5:**
> "Uh you get very strong suspicion. Very good...you get students who...all of a sudden improved a lot uh for some of these cases which suggest uh that it might be Chad writing them instead of the candidate."

*Context: Early identification of AI-generated essays based on sudden English quality improvement*

---

**Quote 6:**
> "The thing is that we had in the past but of course now the AI uh uh you know the text generation becomes way more sophisticated but uh let's say in 2023 2024 still know back then you you could still see that something like a chat GBT generated text was very bland and and generalist. Um, and then these things that I highlighted, you know, the the bit of ambition and so on, uh, the bit of flare, the bit of drive, the bit of focus, reflecting that you've understood the issue, you could still pick that up from from from your better essays. Um, but of course now that that will become more and more difficult"

*Context: Tracking the escalation of AI sophistication and its increasing threat to essay-based assessment; explaining how previous distinguishing features (ambition, flare, drive, focus) become harder to identify*

---

**Quote 7:**
> "So um so what we then need to need needed to do is to actually have an interview with these students uh because then it is you and the interview panel. It's not you and Chad GPT. Um and and then that way you sort of can compare uh what was said in the essay with what what what comes out in an interview. um if there's a big discrepancy there then then then that is an indicator"

*Context: Proposing interviews as a solution mechanism, emphasizing human-to-human verification over text-based assessment*

---

### On Conscious Bias and Context:

**Quote 8:**
> "So look, so so the one thing that one really looks at is and that you need to keep in mind is the so you get students who are really brilliant but you know they did not necessarily have a model ski model C school training. So um their use