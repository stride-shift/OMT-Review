# AI Attitudes Deep Dive

## Dina  Ligaga

Here's a comprehensive analysis of Dina Ligaga's attitudes toward AI and technology in the scholarship review process:

1. AI Statements (Positive/Negative/Neutral):
Positive:
- AI could potentially help with preliminary vetting of applications
- Open to AI assistance that doesn't replace human judgment
- Sees potential for AI to identify which applications need attention

Neutral/Cautious:
- Acknowledges AI's potential emergence in application writing
- Concerned about AI potentially reducing "genuineness" in motivational statements

Negative:
- Worried AI might homogenize or reduce sincerity in applications
- Skeptical about AI fully capturing nuanced human judgment

2. Specific AI Use Cases Mentioned:
- Preliminary vetting of applications
- Pre-populating rubrics
- Identifying which applications need deeper human review
- Potentially screening originality and feasibility of proposals

3. AI Concerns/Fears:
- Loss of "genuineness" in application writing
- Potential reduction of personal, intuitive assessment
- Risk of removing human nuance and tacit understanding
- Fear of standardization that reduces individual uniqueness

4. Trust Conditions for AI:
- Must preserve human ability to modify/override recommendations
- Needs to demonstrate understanding of contextual nuance
- Should augment, not replace, human intellectual work
- Must respect individual applicant's unique narrative

5. Mental Model of AI Capabilities:
- Good at: 
  * Preliminary screening
  * Data aggregation
  * Pattern recognition
- Limited in:
  * Understanding emotional sincerity
  * Capturing complex personal narratives
  * Making holistic judgment calls

6. Technology Comparisons:
- Compared current digital platform (multi-window interface) to previous Excel-based system
- Implied AI similar to previous technological transitions - potentially helpful but not transformative

7. Verbatim Quotes:
On AI's potential:
- "If somebody were to do that part for me and tell me... this person you need to pay attention to them and this person you don't need to pay attention to them."

On AI and genuineness:
- "There's some way you get this feeling and it's become a lot fuzzier with AI interventions"

On preferred AI assistance:
- "I would absolutely [want a] pre-populated rubric... that allows me then to focus on just saying exactly what I think"

Comprehensive analysis shows Dina is pragmatic, cautiously open to AI, but deeply values human intuition and individual narrative complexity.

---

## Edzai Conilias Zvobwo

Here's a comprehensive analysis of the interview transcript's attitudes toward AI and technology in the scholarship review process:

1. AI Statements (Positive/Negative/Neutral):
Positive:
- AI is good at "using rubrics" and "reading documents without emotion"
- AI can help with "mind-numbing" scoring work
- AI can be pre-programmed with contextual instructions

Negative:
- AI "can't reason"
- AI is "purely statistical" and "probabilistic"
- AI lacks empathy and real decision-making capabilities
- Autonomous end-to-end AI systems "don't work"

Neutral:
- AI could potentially assist human reviewers
- AI is currently limited to "statistical pattern matching"

2. Specific AI Use Cases:
- Handling algorithmic/rubric-based scoring
- Initial document screening
- Pre-filtering applications
- Providing initial scores for human review

3. AI Concerns/Fears:
- Lack of nuanced reasoning
- Inability to understand context
- Missing human elements like empathy
- Risk of overlooking complex human narratives
- Potential bias if not carefully designed

4. Trust Conditions:
- Must have "human in the loop"
- Needs pre-programmed contextual instructions
- Requires human oversight and final decision-making
- Must complement, not replace, human judgment

5. Mental Model of AI Capabilities:
- Good at: Pattern matching, rule following, rapid processing
- Bad at: Empathy, complex reasoning, holistic understanding
- Can handle: Algorithmic tasks, initial screening
- Cannot handle: Final decision-making, understanding human stories

6. Technology Comparisons:
- Compares AI to previous manual Excel spreadsheet process
- Suggests AI could be like Bayesian statistics (updating beliefs with evidence)
- Implicitly compares AI to human cognitive processes

7. Relevant Verbatim Quotes:

On AI's Role:
- "AI with a human in the loop where AI does the drudge work"
- "AI is good at using rubrics going to fetch context and actually reading the document without any emotion"

On AI Limitations:
- "AI as it is can't reason"
- "It's purely statistical. It's probabilistic. It doesn't even understand what it's doing itself"
- "Things that don't require intangibles like empathy and actual decision making should be in the domain of the human"

On Ideal AI Implementation:
- "Pre-program it and give it quant South African context such that it can go in and actually use that as a rubric"
- "Leaving room for the human to actually review and almost give a second opinion"

This analysis reveals a nuanced, pragmatic view of AI as a supportive tool that must be carefully constrained and always supervised by human judgment.

---

## Freedom Gumedze

Based on the transcript, here's a comprehensive analysis of Freedom Gumedze's attitudes toward AI and technology in the scholarship review process:

1. AI Statements:
- No direct statements about AI were made
- No explicit mentions of AI in the review process

2. Use Cases for AI:
- None discussed

3. AI Concerns/Fears:
- None expressed

4. Trust Conditions:
- Would require an assistant to:
  * Dig out research metrics
  * Summarize academic backgrounds
  * Create checklists
  * Verify school/career alignment
- Emphasized wanting to still personally read the portfolio

5. Mental Model of AI/Technology:
- No clear mental model discussed
- Showed openness to technological assistance
- Values human judgment in review process

6. Technology Comparisons:
- Compared review processes across:
  * NRF (National Research Foundation)
  * University of Cape Town
  * Other international funding bodies
- Discussed various research metric technologies:
  * Google Scholar
  * Scopus
  * Biblometrics

7. Relevant Verbatim Quotes:
- "I would like someone assistant maybe to dig up that information"
- "I still think as a reviewer you still want to read the portfolio"

Overall, while the transcript doesn't reveal direct AI attitudes, it suggests an openness to technological assistance while maintaining human oversight in the review process.

---

## Frelet De Villiers

Based on the transcript, here's a comprehensive analysis of AI attitudes:

AI Statements:
1. Primarily Negative/Skeptical Attitudes
- Views AI as potentially unreliable for substantive judgment
- Distrusts AI's ability to understand nuanced context
- Sees AI as potentially compromising authenticity

2. Specific AI Mentions:
- References AI's potential use in generating reference letters
- Acknowledges AI's capability in text generation

3. Specific Use Cases Mentioned:
- Potential assistive role in initial document screening
- Possible preliminary consistency checking
- Potential first-pass review for basic requirements

4. Trust Conditions:
- Would only trust AI for very mechanical tasks
- Requires human oversight/final judgment
- Must not replace human expertise and contextual understanding

5. Mental Model of AI Capabilities:
- Good at pattern matching
- Can handle basic administrative tasks
- Insufficient for nuanced evaluation
- Lacks personal experience/contextual comprehension

Key Verbatim Quotes:
"The assistance we need is the people that go through applications and see that minimum requirements are met."

"We will never be on the same level of thinking of conceptualization of experience."

"I will not trust an assistant."

"Especially with AI these days even the reviewer... can put that through AI and I mean you can't even see if it's a student writing or whatever."

Comparison to Other Technologies:
- Compares AI to existing review platforms
- Highlights user interface advantages of digital platforms
- Sees AI as another technological tool, not a complete solution

Underlying Philosophical Stance:
- Values human judgment
- Believes expertise cannot be fully replicated
- Prioritizes individual interpretation and emotional intelligence

Concerns:
- AI might generate inauthentic content
- Could miss nuanced contextual details
- Potential for masking true authorship

Overall, the interviewee maintains a cautiously skeptical but not entirely dismissive view of AI's potential role in academic review processes.

---

## Martin Clark

Here's a comprehensive analysis of Martin Clark's attitudes toward AI in the scholarship review process:

1. AI Statements (Valence):
Positive:
- "I love AI" (early in transcript)
- "I'm a big believer that AI can help in almost any element"
- Sees significant potential utility in AI

Neutral/Nuanced:
- Acknowledges AI's potential while recognizing implementation challenges
- Wants careful, measured AI integration

2. Specific AI Use Cases:
- Logic validation
- Stakeholder perception assessment
- Data scraping
- Source verification
- Subject matter expertise expansion
- Presenting candidate value
- Helping understand complex technical details outside adjudicator's expertise

3. AI Concerns/Fears:
- Uneven AI usage among adjudicators
- Potential for wrong answers
- Inconsistent server connections
- Potential bias in implementation
- Questioning whether individual AI proficiency varies

4. Trust Conditions:
- Needs consistent implementation
- Requires human verification
- Must supplement, not replace, human judgment
- Needs transparent sourcing
- Must be used equitably across review process

5. Mental Model of AI Capabilities:
- Sees AI as a sophisticated research/analysis assistant
- Views AI as complementary to human expertise
- Recognizes AI's pattern recognition capabilities
- Understands AI's current limitations

6. Technology Comparisons:
- Compares AI to "Coles Notes" (summarization tool)
- Implicitly contrasts AI with rigid rubric scoring

7. Key Verbatim Quotes:
"AI could be helpful for logic validation, data scraping, and verifying sources"

"Sometimes I will ask my own AI to verify or validate the type of logic that I'm applying"

"An AI depending on how it's implemented can also help present the candidate"

"A caveat of AI is that you don't always have connection to the servers and AIs... can give wrong answers"

The analysis reveals a sophisticated, nuanced perspective emphasizing AI as a collaborative tool rather than a replacement for human expertise.

---

## Maureen De Jager

Here's a comprehensive analysis of Maureen De Jager's attitudes toward AI in the scholarship review process:

1. AI Statements (Overall Sentiment):
Positive/Neutral:
- Acknowledges potential administrative utility
- Open to AI for initial filtering and summaries
- Recognizes AI can generate convincing proposals

Negative/Cautious:
- "Slightly distrustful of AI"
- Emphasizes the "interpretative" nature of creative assessment requires human judgment
- Concerned about AI potentially undermining genuine application quality

2. Specific AI Use Cases Mentioned:
- Initial document filtering
- Checking application completeness
- Generating administrative summaries
- Generating international program information summaries
- Prepopulating administrative sections of rubrics

3. AI Concerns/Fears:
- AI might generate convincing but superficial proposals
- Risk of applicants becoming "instrumentalist" in responses
- Potential loss of nuanced human interpretation
- Concerns about AI-generated writing samples
- Fear of over-reliance on algorithmic assessment

4. Trust Conditions for AI:
- Must not replace human interpretative judgment
- Should assist, not determine
- Needs transparent limitations
- Must preserve assessment complexity

5. Mental Model of AI Capabilities:
- Good at: Administrative tasks, filtering, summarizing
- Limited in: Interpreting creative practice
- Cannot replace holistic human assessment
- Potential for generating coherent but shallow content

6. Technology Comparisons:
- Compared AI to previous screening mechanisms
- Implied AI similar to administrative summary tools

7. Verbatim Quotes:
"With AI, it's very easy to write a convincing proposal for a research project"

"So much of this is interpretative... creative practice is such a tricky thing"

"I would be nervous of an over-reliance on things that really do require a kind of interpretative mindset"

"Looking at anything to do with art takes time and that's just what one signs up for... it requires a human element of interpretation"

Conclusion: Maureen sees AI as a potential administrative assistant but strongly believes human judgment remains irreplaceable in creative assessment.

---

## Mohamed Cassim

Here's a comprehensive analysis of Mohamed's attitudes toward AI in the scholarship review process:

1. Statements About AI (Positive/Negative/Neutral):
Positive:
- AI can help with binary/factual tasks efficiently
- AI could reduce "superfluous cognitive load"
- AI can perform quick database searches
- AI could assist with initial fact-finding

Negative/Cautionary:
- AI is "poorly equipped" to determine future probability
- AI is biased toward solving "yesterday's problems"
- AI can't assess human capability for future delivery
- AI-generated letters lack authenticity

2. Specific AI Use Cases:
- Budget fact-checking
- Verifying topic uniqueness across academic databases
- Psychographic candidate analysis
- Checking institutional performance against candidate claims
- Reference letter verification
- Initial document screening

3. AI Concerns/Fears:
- Overreliance on historical data
- Inability to understand human potential
- Risk of missing nuanced human capabilities
- Potential for generating inauthentic documents
- Loss of human judgment in assessment

4. Trust Conditions for AI:
- Must handle strictly factual/binary tasks
- Should supplement, not replace human evaluation
- Needs transparent data sources
- Must acknowledge limitations in predicting human performance

5. Mental Model of AI Capabilities:
- Strong at: Data processing, fact retrieval, pattern matching
- Weak at: Understanding human potential, future prediction, nuanced assessment
- Sees AI as a "cognitive assistant" rather than a decision-maker

6. Technology Comparisons:
- Compares AI to a "cognitive assistant"
- Implies AI is similar to other digital tools but with significant limitations
- Suggests AI is like a sophisticated search/analysis tool

7. Relevant Verbatim Quotes:

On AI's Limitations:
"AI right now in my own view is built on data that is in the internet... by its very nature AI would go on historic trends when all of us sitting at this table know that the future is not told by history alone."

On AI's Potential:
"I think it could be helpful if [handling] the binary stuff... The AI could answer that in about 30 seconds and the adjudicator can decide on the back of that."

On AI as an Assistant:
"From the cognitive perspective, it would be fantastic if it said the topic requires an extrovert of this kind with that type of experience and this guy doesn't have it."

Overall, Mohamed sees AI as a powerful but limited tool - useful for initial screening and fact-finding, but fundamentally incapable of the nuanced human judgment required in scholarship assessment.

---

## Philippe Burger

Here's a comprehensive analysis of the interview transcript focusing on attitudes toward AI and technology in the scholarship review process:

1. Statements about AI (Positive, Negative, Neutral):
Positive:
- Potential utility in process improvement
- Recognition of advancing AI capabilities

Negative:
- Concern about AI-generated essays undermining assessment
- Suspicion of AI's role in essay writing
- Potential for bland, generic content

Neutral:
- AI as an emerging technological factor in evaluation

2. Specific Use Cases for AI:
- Essay writing/generation
- Potential pre-screening of applications
- Potential supplementary assessment tool

3. Specific Concerns/Fears About AI:
- Reduced ability to assess genuine student motivation
- Loss of nuanced understanding of applicant's background
- Difficulty distinguishing authentic from AI-generated content
- Potential homogenization of application essays

4. Trust Conditions:
- Requires human verification
- Needs supplementary assessment methods
- Must demonstrate alignment with applicant's actual capabilities
- Requires interview/proctored validation

5. Mental Model of AI Capabilities:
- Can generate syntactically correct text
- Capable of producing generic, bland content
- Increasingly sophisticated text generation
- Limited in capturing nuanced personal motivation

6. Technology Comparisons:
- AI essay generation compared to traditional essay writing
- Parallel drawn with Turnitin's AI detection capabilities
- Compared to oral defense processes in academic settings

7. Relevant Verbatim Quotes:

On AI Essay Detection:
"...you get very strong suspicion. Very good."

On AI Essay Limitations:
"...in 2023 2024 still know back then you you know you could still see that something like a chat GBT generated text was very bland and and generalist."

On Future Challenges:
"...going forward I think that you're going to have a serious problem relying on essays as a mechanism for distinguishing between applicants..."

Proposed Solutions:
"...maybe interviews or something like that... a timed out essay, you know, you say log on in at 9:00 and you have 25 minutes and you do it under some proctoring..."

The analysis reveals a nuanced, pragmatic approach to AI's role in scholarship assessment, emphasizing human judgment and contextual understanding as critical complementary elements.

---

## Pieter Pistorius

Here's a comprehensive analysis of Pieter Pistorius's attitudes toward AI in the scholarship review process:

1. AI Statements (Attitudes):
Positive:
- AI could be "useful" for initial screening
- Sees AI as helpful for "giving structure to an issue"
- Thinks AI might help reduce "superfluous cognitive load"

Neutral/Skeptical:
- "Somewhat cynical about AI"
- Believes AI should assist, not make final decisions
- Wants human oversight in final evaluation

Negative:
- Concerned about potential complexity of AI measurements
- Worried about needing to explain AI's multiple measurements

2. Specific AI Use Cases:
- Initial application screening
- Identifying low-caliber applications
- Compiling academic timelines
- Detecting gaps in academic/career histories
- Standardizing diverse academic record formats

3. AI Concerns/Fears:
- Potential for additional complexity
- Risk of multiple conflicting measurements
- Potential loss of nuanced human judgment
- Academic integrity issues (mentions catching AI-generated student reports)

4. Trust Conditions for AI:
- Must not make final decisions
- Should provide structure/initial screening
- Needs human verification
- Must demonstrate clear value-add

5. Mental Model of AI Capabilities:
- Good at: 
  * Pattern recognition
  * Initial sorting/screening
  * Timeline compilation
  * Standardizing information

- Cannot:
  * Understand deeper motivational nuances
  * Make holistic human judgments
  * Replace critical human evaluation

6. Technology Comparisons:
- Compares AI to measurement processes
- Views AI similar to rubric scoring: helpful but limiting

7. Verbatim Quotes:
"Eventually the human being must make a final call."

"It probably wouldn't do any harm... it may make sense."

"AI is a significant deal... it's a very useful technique and it helps you to give some structures to an issue."

"You could hypothetically compile a comprehensive report just using AI... but eventually the human being must make a final call."

The analysis reveals a pragmatic, nuanced perspective that sees AI as a potential assistant but not a replacement for human judgment in scholarship reviews.

---

## Ryan Nefdt

Analysis of AI and Technology Attitudes in the Transcript:

1. Statements About AI (Attitudes):
Positive:
- Open to potential AI assistance for providing context
- Interested in large language models and AI research
- Sees potential for AI to help flag inconsistencies

Neutral/Cautious:
- "I'm a bit of a lite when it comes to that" (regarding AI)
- Worried about AI summarization capabilities
- Skeptical but not dismissive

Negative: None explicitly stated

2. Specific AI Use Cases Mentioned:
- Providing discipline-specific context
- Flagging inconsistencies in submissions
- Helping translate complex academic concepts
- Bridging understanding across different academic domains

3. AI Concerns/Fears:
- Potential for inaccurate summarization
- Risk of losing nuanced understanding
- Cultural translation challenges
- Potential bias introduction

4. Trust Conditions for AI:
- Must provide objective, contextual information
- Should not replace human judgment
- Must be able to handle discipline-specific nuances
- Needs to help, not oversimplify complex work

5. Mental Model of AI Capabilities:
- Can assist with contextual information
- Can flag potential inconsistencies
- Limited in fully understanding complex theoretical work
- Not capable of fully replacing human evaluation

6. Technology Comparisons:
- Compares AI potential to recommendation letter systems
- Views AI as potentially similar to a knowledgeable research assistant

7. Verbatim Quotes:
On AI Assistance:
- "Maybe if there was some sort of assistant who could give you context of the discipline..."
- "This assistant could bridge a part of that gap..."
- "If the tool could identify inconsistencies..."

On AI Limitations:
- "I'm a bit worried about the kind of summarization..."
- "I don't always know background terms..."

Comprehensive nuanced analysis highlighting Ryan Nefdt's sophisticated, balanced perspective on potential AI technological augmentation in academic review processes.

---

## Frasia Oosthuizen

Based on the transcript, here's a comprehensive analysis of Frasia Oosthuizen's attitudes toward AI and technology in the scholarship review process:

AI Statements:
1. Neutral/Skeptical Mentions:
- Mentioned AI could potentially write motivation letters: "I know people write motivations and you can probably AI it as well"
- Generally cautious about pre-processing or pre-interpretation of applications

2. Use Cases for AI (Potential):
- Potentially pre-filling academic performance data
- Potentially categorizing/organizing application materials
- Potentially generating a layman's abstract alongside scientific proposal

3. Specific Concerns/Fears About AI:
- Worried about introducing pre-existing bias
- Fears losing personal judgment/objectivity
- Concerned about AI creating a "preconceived judgment"

4. Trust Conditions:
- Must not replace her personal review process
- Must preserve her ability to form independent assessments
- Should only provide supportive, non-interpretive information

5. Mental Model of AI Capabilities:
- Sees AI as potentially useful for administrative/organizational tasks
- Believes AI cannot fully capture nuanced human judgment
- Views AI as a potential tool, not a replacement for human review

6. Technology Comparisons:
- Compares AI potential to current review processes
- Appreciates current digital/online review system
- Values human interpretive capabilities over algorithmic assessment

Key Verbatim Quotes:
- "I prefer making those judgment calls because I want I don't want someone else to have told me"
- "If someone else have already created that picture I come in with that person's preconceived judgment"
- "If that person tells me what the red flags are, I already have decided in my mind no this is not going to work"

Overarching Attitude: Cautiously open to technological assistance, but deeply committed to preserving human judgment and individual review integrity.

---

