# AI Attitudes Deep Dive

## Dina  Ligaga

# Analysis of Attitudes Toward AI and Technology in Scholarship Review

## 1. STATEMENTS ABOUT AI (All Mentions)

### Positive/Exploratory Statements
- **00:00:56** - Willing to explore how "AI can support that decision making process and reduce noise and bias potentially from that"
- **00:08:17-00:09:30** - Open to the idea that AI could assist in initial screening: "it would just be are they you know give I don't know...if somebody were to do that part for me"
- **00:37:18-00:38:21** - Strong endorsement of pre-populated rubric from trusted source: "Absolutely. Absolutely."

### Negative/Cautionary Statements
- **00:08:17** - Expresses concern about AI-generated authenticity in applications: "it's become a lot fuzzier with AI interventions where you know that somebody...there's a genuiness to some of the some of the applications that I appreciate"
- **00:08:17** - Notes detection challenge: "I'm not saying that's what's happened because I think there's an area where they can actually say I used AI or not but there's a genuiness to some of the applications"

### Neutral/Uncertain Statements
- **00:00:00** - Initial confusion about AI: "I don't think it's ours. Um, I don't think we need it...I don't I don't know what that is"

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

### Primary Use Case: Preliminary Vetting/Filtering
- **00:35:58** - "The helpful assistance would be in preliminary vetting—identifying which applications need attention and which do not, focusing on originality and feasibility"
- **00:35:58-00:37:18** - "if somebody were to do that part for me and tell me look I've looked at what they want to do and I've looked at what they have done and I think given what I've read this person you know you need to pay attention to them and this person you don't need to pay attention to them. Um you know that would be quick. I would probably go through a lot more applications"

### Secondary Use Case: Pre-Populated Rubric Completion
- **00:37:18** - "having a pre-populated rubric from a trusted source would be helpful, allowing them to focus on the narrative feedback"
- **00:38:21** - "if that trusted thinking partner said, 'Here, I've done the marking of the rubric.' Would that be a help to you...Absolutely."

### NOT Suggested for AI:
- **00:34:38** - The actual reading and evaluation: "the fun part is the actual reading and evaluating of the proposals"
- **00:35:58** - Final judgment calls: "I enjoy reading good proposals"

---

## 3. SPECIFIC CONCERNS AND FEARS ABOUT AI

### Authenticity/Genuineness Detection
- **00:08:17** - "it's become a lot fuzzier with AI interventions where you know that somebody I'm not saying that's what's happened because I think there's an area where they can actually say I used AI or not but there's a genuiness to some of the some of the applications that I appreciate"
- Implicit concern: AI-written motivations may lack the sincerity she values in applications

### Delegating Critical Judgment
- **00:35:58** - Expresses uncertainty about how to appropriately delegate: "I don't know how one weeds out That's that's the thing. I don't know how one makes that call"
- **00:35:58** - Fear of missing good applications: "I enjoy reading good proposals but sometimes they're like one in every three or one in every five"
- **00:36:58** - Worries about losing visibility: "say I had a research assistant who would tell me uh-uh no not worth your and then you know this one perhaps read this read this um out of 20 I read six"

### Loss of Autonomy
- **00:21:00** - Concern that rubric "boxes me in" - extension to AI could amplify this: "the rubric for me then then takes it kind of boxes me in"
- **00:38:21** - Requires reassurance: "I also do need to have the kind of leeway or at least know that I could change something if I didn't agree"

---

## 4. TRUST CONDITIONS THEY DESCRIBE

### Requirements for Trusting AI/Tools
- **00:00:56** - Confidentiality and candor: "we're not sharing this transcript with OMT...full confidentiality...you speak as candidly about your process as possible"

- **00:26:45-00:29:08** - Trust in collegial synthesis: "somebody who perhaps has also reviewed the same documents as me and and that that then makes it possible for the person sitting on the other side to then make that call. So um I'm comfortable in that"

- **00:38:21** - Requires transparency and override ability: "if that happened but I still had the power to change the things on the rubric but at least I have some kind of you know some kind of filled up rubric...I also do need to have the kind of leeway or at least know that I could change something if I didn't agree"

- **00:35:58-00:36:58** - Source matters: "it would just be are they you know give I don't know how to answer that in one sentence. So look is the person deserving so for me it's about the project they want they're proposing is it a original is it doable is it all the things. So if somebody were to do that part for me and tell me look I've looked at what they want to do"

### Trust Conditions NOT Met:
- Loss of discretion: **00:38:21** - "I do need to have the kind of leeway"
- Blind recommendations without explanation capability: **00:35:58** - worries about being told to skip applications without understanding why

---

## 5. MENTAL MODELS OF WHAT AI CAN/CANNOT DO

### What AI Can Do (In Her Model)
- **00:35:58** - Evaluate originality and feasibility: "the helpful assistance would be in preliminary vetting—identifying which applications need attention and which do not, focusing on originality and feasibility"
- **00:38:21** - Score rubric dimensions: "if that trusted thinking partner said, 'Here, I've done the marking of the rubric'"
- Speed up process: **00:35:58** - "I would probably go through a lot more applications"

### What AI Cannot/Should Not Do (In Her Model)
- **00:34:38** - Actual evaluation of proposals: "the fun part is the actual reading and evaluating of the proposals" (implies this is uniquely human)
- **00:08:17** - Authenticity assessment: "it's become a lot fuzzier with AI interventions" (suggests AI struggles with detecting sincerity)
- **00:35:58** - Make final recommendations: "I don't know how one makes that call" (final judgment is human-only)
- Deterministic weeding: **00:35:58** - "I don't know how one weeds out" (filtering requires human discretion)

### Limitations She Recognizes
- **00:35:58** - "it's really difficult though because you know you have to have read right" (AI must actually understand applications deeply)
- **00:35:58-00:37:18** - Risk of missing nuance: "I enjoy reading good proposals but sometimes they're like one in every three or one in every five"

---

## 6. COMPARISONS TO OTHER TECHNOLOGIES/PROCESSES

### Comparison to Previous Review Process (with Other Humans)
- **00:04:41** - Old system: "we worked with Excel sheets...there was a bit of comparison going on"
- **00:29:08** - Old system benefit: "I could talk to my colleagues about why they made the decision"
- **00:29:08** - Old system drawback: "It was slower, much much slower"
- **00:29:08** - Her verdict: "I often find that it mies the water" (comparative task is unhelpful)
- **00:29:08** - What she preferred: "I'm not going to change my mind because the other person says something else but I just like to know that I wasn't too far off right"

### Comparison to Current Platform
- **00:06:03** - Multi-window frustration: "one of the things that I found um frustrating is the multi-window um um interface where you have to open different windows"
- **00:06:03** - Speed trade-off: "the new system which in many ways has been

---

## Edzai Conilias Zvobwo

# Analysis of AI and Technology Attitudes in Scholarship Review Process

## 1. STATEMENTS ABOUT AI (Positive, Negative, Neutral)

### POSITIVE STATEMENTS
- AI excels at objective scoring tasks
- AI is good at using rubrics
- AI can read documents without emotion
- AI can help with "mind-numbing" and "drudge work"
- "Human in the loop" model is ideal for AI support
- AI can handle statistical pattern matching effectively
- Natural language processing capabilities are now functional

### NEGATIVE STATEMENTS
- AI cannot reason (fundamental limitation)
- AI cannot display empathy
- AI cannot handle actual decision-making
- Autonomous end-to-end systems don't work
- AI is "purely statistical" and "probabilistic"
- AI doesn't understand what it's doing itself
- AI is not suitable for tasks requiring intangibles
- Current AI is unsuitable for tasks requiring genuine understanding

### NEUTRAL STATEMENTS
- AI requires pre-programming with system prompts
- AI needs South African context as a rubric
- AI operates through pattern matching in natural language
- AI can be integrated into human review processes

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

1. **Rubric Scoring**: Managing the algorithmic, programmable scoring element of applications
2. **Mind-numbing Work**: Handling repetitive scoring that becomes "fuzzy" over time
3. **Document Analysis**: Reading applications without emotional bias
4. **Contextual Pattern Matching**: Using rubrics with South African context guidelines
5. **First-Pass Assessment**: Performing initial scoring before human review
6. **Drudge Work**: Automating "the drudge work the mind numbing stuff"
7. **Statistical Analysis**: Tasks requiring pattern recognition across documents

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

| Concern | Verbatim Evidence |
|---------|------------------|
| **Lack of reasoning capability** | "AI as it is can't reason" / "the systems can't necessarily reason" |
| **No genuine understanding** | "It doesn't even understand what it's doing itself" |
| **Cannot handle empathy** | "things that don't require you know uh intangibles like empathy" |
| **Cannot make actual decisions** | "actual decision making should also be uh in the domain of the human because AI is not there yet" |
| **Autonomy doesn't work** | "autonomous end to end doesn't work" |
| **Statistical limitations** | "It's purely statistical. It's probabilistic." |
| **Missing human judgment** | Cannot assess "personal story," "resilience," "between the lines analysis" |
| **Context blindness** | Cannot understand South African impact context intuitively |

---

## 4. TRUST CONDITIONS THEY DESCRIBE

### CONDITIONS FOR TRUSTING AI:
1. **Human oversight model**: "AI with a human in the loop"
2. **Proper pre-programming**: System prompts with clear instructions and South African context
3. **Limited scope**: Only for "algorithmic," "programmable" tasks
4. **Subject matter limitation**: Not for decision-making requiring empathy or intuition
5. **Second opinion availability**: "leaving room for the human to actually review and uh and almost almost almost give a second opinion basically"
6. **Clear rubric application**: Following explicit, detailed, algorithmic guidelines
7. **Pattern-matching only**: Tasks that don't require understanding or reasoning

### CONDITIONS FOR NOT TRUSTING AI:
- Autonomous decision-making
- Tasks requiring empathy, understanding, or reasoning
- Final determinations on scholarships
- Assessment of personal narratives or resilience
- Judgment calls about implicit information
- Context-specific reasoning about South African impact

---

## 5. MENTAL MODEL OF WHAT AI CAN/CAN'T DO

### WHAT AI CAN DO:
- **Pattern matching**: Statistical and probabilistic identification of patterns
- **Document processing**: Read and analyze text systematically
- **Rubric application**: Apply pre-defined rules and criteria consistently
- **Eliminate emotion**: Score without personal bias affecting numerical outputs
- **Natural language processing**: Write, analyze, and extract from text
- **Objective scoring**: Apply algorithmic criteria repeatedly
- **First-pass filtering**: Provide initial assessments based on criteria

### WHAT AI CANNOT DO:
- **Reason**: "AI as it is can't reason"
- **Understand context**: Cannot genuinely grasp South African development needs
- **Display empathy**: Cannot resonate with personal stories
- **Make decisions**: Cannot make final judgments requiring wisdom
- **Read between lines**: Cannot infer implicit meaning or potential
- **Understand itself**: "doesn't even understand what it's doing itself"
- **Handle intangibles**: Cannot assess resilience, grit, or character growth
- **Make judgment calls**: Cannot decide when to override scoring based on implicit understanding
- **Assess deserving-ness**: Cannot determine social justice or need dimensions

### CRITICAL DISTINCTION:
Edzai explicitly distinguishes between:
- **What AI is**: Statistical probability engine
- **What AI isn't**: Reasoning, understanding, decision-making entity
- **What matters in review**: Human judgment on non-automatable elements

---

## 6. COMPARISONS TO OTHER TECHNOLOGIES OR PROCESSES

### Comparison to Manual/Excel System:
- "the past year was the first time that we used software. Um, previously we we we did it manually uh with an Excel Excel spreadsheet. So, I think uh the software was quite was quite convenient."

### Comparison to Bayesian Statistics:
- "So it's Beijian. Uh you change your beliefs as you as you gather more evidence basically. So now that you've done a few you've got more evidence, you've got a trend then you can go back and actually um um uh correct for that."

### Comparison to Two-Fellow Process:
- "I think it's quite profound uh because it's it's it's quite uh you know what the McKenzie people would tell you it's missy mutually exclusive cumulatively exhaustive... it almost mirrors uh because Tracy and I are both to fellows by the way. So so the two fellow process is almost kind of similar... you have three four people uh doing the same uh cohort and then averaging out"

### Implied Comparison to Human-Only Review:
- Current system with AI assistance would be more consistent than purely human review (emotion-free scoring)

---

## 7. VERBATIM QUOTES - COMPREHENSIVE EXTRACTION

### ON AI'S ROLE AND CAPABILITIES

**Core Position:**
- "I'm insisting on on on human in the loop. uh autonomous end to end doesn't work"
- "AI as it is can't reason. You know CH GPT can write paragraphs and articles and all that. It's purely statistical. It's probabilistic. It doesn't even understand what it's doing itself."
- "we can only do things that uh require statistical pattern matching"
- "things that don't require you know uh intangibles like empathy and actual decision making should also be uh in the domain of the human because AI is not there yet maybe one day but it's not there"

**On Scoring:**
- "this is a mind-numbing process I mean going through those sometime now you is this a four is this a three you know it becomes fuzzy along the way"
- "If AI can actually help with the with with the scoring elements that is um uh as objective as possible, I think that would help because Yeah. because they become just numbers afterwards after some time."
- "because with AI you you actually need to pre have a have a have a system prompt literally where uh those instructions that we get from from OMT where it says okay we're adjudicating based on uh this this this and you know you know that and then you pre-program it and give it quant South African context such that it can go in and actually um use that as a rubric."
- "AI is good at using uh rubrics going to fetch context and actually reading uh the document without any emotion"
- "the way they've done it, it's so detailed and uh algorithmic that it can it's programmable basically"

**On the Ideal Model:**
- "I would suggest a situation where there is uh AI with a human in the loop where AI does the drudge work the mind numbing stuff with G but leaving room for the human to actually uh review and uh and almost almost almost give a second opinion basically."

**On Specific AI Limitations:**
- "Maybe even the the statement that you said Justin where you said AI reasoning right now as it stands I've just written a book about it by the way. Uh AI as it is can't reason."

### ON HUMAN JUDGMENT AI CANNOT REPLICATE

**Personal Stories:**
- "on the personal story uh where um applicants are trying to show their resilience their story where uh they came from a broken home and uh against all odds

---

## Freedom Gumedze

# Analysis of AI and Technology Attitudes in Scholarship Review

## CRITICAL FINDING
**This transcript contains NO discussion of AI or artificial intelligence.** The interview focuses entirely on human review processes, judgment calls, and scholarship assessment mechanisms. There are no mentions of AI tools, machine learning, automation, or algorithmic assessment.

---

## 1. STATEMENTS ABOUT AI
**None found.** Zero references to AI, machine learning, algorithms, automation, or computational assessment tools.

---

## 2. SPECIFIC USE CASES FOR AI
**None mentioned.**

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI
**None stated.**

---

## 4. TRUST CONDITIONS REGARDING AI
**Not applicable** - no trust conditions for AI are discussed because AI is not mentioned.

---

## 5. MENTAL MODEL OF WHAT AI CAN/CAN'T DO
**Not discussed.**

---

## 6. COMPARISONS TO OTHER TECHNOLOGIES
**None to AI specifically.** 

However, there are comparisons to *information systems and data sources* (not AI):
- Google Scholar vs. Scopus for publication assessment
- Biblometrics systems for evaluating scholar impact
- How different institutions (NRF, universities, MRC UK, EU) approach scoring and evaluation

---

## 7. RELEVANT VERBATIM QUOTES ABOUT TECHNOLOGY/AI

**There are NO verbatim quotes about AI.** However, relevant quotes about assessment and information tools (non-AI) include:

**On Publication Assessment Tools:**
- "you're not told how you should do this publication. Should you be looking at Google Scholar? should be scopas."
- "Google square will just give you everything that's coming through but it will not tell you whether this is published in a very good journal. It's going to pick up something from MDPI or something."
- "at my university something called biblometrics where you actually look at what the impact of the scholar is what are the networks what are what are their sort of like collaborations"

**On Systematic vs. Judgment-Based Assessment:**
- "it's built on a model um I'm I'm sorry to say this but it's built on a NRF"
- "Something similar I would apply something similar here just to sort of try and benchmark"
- "I don't look at the current pool that in this pool this is the this is the best"
- "you really have to apply your mind as to are this good publications"
- "it's only if you you are familiar with assessing the quality of research otherwise you can just look at the numbers and say h index of 30 this person is a very good when in fact what they are publishing is just it's just not up to standard."

**On Delegating Assessment Tasks (Notably: Human Assistant, Not AI):**
- "if it's not in the if it's not it is going to be in the pack, they're going to list that they're going to list their papers"
- "I would like someone assistant maybe to dig up that information"
- "what I would like there is perhaps just a summary of their academic background"
- "It's really maybe just a checklist. Are these things there for this?"

---

## KEY INSIGHT
This interview reveals a human-centric review process emphasizing **expert judgment, contextual knowledge, and deliberative assessment**—notably without any reference to or consideration of AI tools. The interviewee's discussion of what they *would delegate* (data gathering, checklist verification) to a human assistant suggests areas where automation *could* theoretically apply, but this is never articulated as an AI opportunity or concern.

---

## Frelet De Villiers

# Analysis of AI and Technology Attitudes in Scholarship Review Interview

## 1. STATEMENTS ABOUT AI (All Mentions)

### Negative/Concerned Statements:
- **General concern about AI's opacity in reference letters**: "and especially with AI these days even the reviewer or or the you know the reference referee um can also put that through AI and I mean you can't even see if it's a it's a student writing or whatever"

### Neutral/Factual Statements:
- **Acknowledgment of AI's existence as a tool**: Recognition that AI exists and is being used in academic contexts, but treated as a problem to manage rather than a solution to employ

### Positive Statements:
- **None identified** - No positive statements about using AI in the review process

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

**Only one use case mentioned - and it's external/problematic:**
- Reference letters being run through AI by referees or students to generate or enhance written content
- Context: "even the referee or the you know the reference referee um can also put that through AI"

**No proposed or welcomed use cases for AI in the reviewer's own process**

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

### Detection/Authenticity Concerns:
- **"you can't even see if it's a it's a student writing or whatever"** - Fear that AI-generated content cannot be distinguished from human-written content
- **Loss of genuine insight** - AI-generated reference letters may obscure the authentic voice and genuine assessment of a supervisor
- AI threatens to undermine the credibility signals reviewers rely on (generic vs. detailed reference letters)

### Implicit Concerns:
- **Undermines trust mechanisms** - If references can be AI-generated, the reviewer's ability to trust this key evaluative tool is compromised
- **Cannot control or verify AI output** - Unlike human assistants, AI decisions would be opaque and potentially inconsistent with reviewer values
- **Substitution anxiety** - AI might replace human judgment in ways that don't align with the reviewer's values and decision-making framework

---

## 4. TRUST CONDITIONS DESCRIBED

### What the Reviewer Trusts:
1. **Face value acceptance with verification responsibility**: "you have to believe what you get and you also have to believe the facts that you get"
2. **Personal integrity accountability**: "If if they lie to me it's on their black book" - trusts applicants to self-regulate through shame/reputation
3. **Other humans' expertise**: "if I'm not sure about something, I will go and ask an expert in a certain field"
4. **Direct human judgment**: Trusts her own cognitive processes and those of other disciplinary experts

### What the Reviewer Won't Trust:
1. **Assistants with decision-making authority**: "I will not work as an assistant... I mean what will the assistant be able to do?"
2. **Third parties with different values**: "if it's a red flag for the assistant, it's not necessarily a red flag for me because we will never be on the same level of thinking of conceptualization of experience"
3. **Proxies for human judgment**: Won't delegate the evaluative function to anyone, including intelligent assistants
4. **Timeline dependencies**: "the other thing is they don't always stick to your timeline. So now I have to wait for the assistant to come back to me and in the meantime I would have been finished already"

---

## 5. MENTAL MODEL OF WHAT AI CAN/CAN'T DO

### What AI Cannot Do (Per Reviewer's Model):
- **Cannot understand context and values**: "we all have our unique set of values and our unique set of what you expect"
- **Cannot make evaluative judgments**: Cannot truly "review" applications with the nuance required
- **Cannot replicate human judgment**: "they cannot review. They cannot I don't know"
- **Cannot match disciplinary expertise**: Won't trust AI to understand field-specific quality markers
- **Cannot be aligned with reviewer's standards**: "if it's a red flag for the assistant, it's not necessarily a red flag for me"

### Implicit Assumptions About AI:
- **AI as tool for grunt work only**: "not just their ability to do um to do grunt work or pattern matching" - acknowledges AI excels at pattern matching but sees this as insufficient
- **AI as opaque black box**: Cannot explain its reasoning in ways that match human conceptualization
- **AI as unreliable for consistency**: Might flag things inconsistently with reviewer's expertise-based judgment

### What AI Might Theoretically Do (But Reviewer Resists):
- Identifying minimum requirements compliance
- First-pass content review for inconsistencies
- Flagging inflated budgets/red flags
- Doing preliminary research on unfamiliar disciplines
- **Reviewer's response**: Explicitly rejects all of these, preferring direct expert consultation

---

## 6. COMPARISONS TO OTHER TECHNOLOGIES OR PROCESSES

### Technology Comparison - NRF vs. OMT Platforms:
- **NRF (negative example)**: "the NRF where you have a PDF and then you have to scroll through absolutely everything and then your rubric is another document"
- **OMT (positive example)**: "the Openheimer's website um is really um very user friendly because you can have the split screen and and everything is really available"
- **Implicit lesson**: Interface design and information architecture matter; good technology removes *superfluous* cognitive load while preserving core judgment

### Process Comparison - Human Assistance:
- Rejects the model of delegating to assistants
- Contrasts with her own practice of consulting disciplinary experts directly
- "I will not trust an assistant... if I'm not sure about something, I will go and ask an expert in a certain field"

### No Comparison to AI Systems Directly:
- No mention of ChatGPT, LLMs, or specific AI tools
- AI mentioned only as something others use (referees with reference letters), not as a potential tool for reviewers

---

## 7. ALL RELEVANT VERBATIM QUOTES (Organized by Theme)

### AI Detection and Authenticity:
1. **"and especially with AI these days even the reviewer or or the you know the reference referee um can also put that through AI and I mean you can't even see if it's a it's a student writing or whatever"**

2. **"So um yeah you you have to believe what you get and you also have to believe the facts that you get"** - (resignation about unverifiable AI use)

3. **"I mean so I I I always have I have the philosophy um that is on their black book. If if they lie to me it's on their black book"** - (strategy for dealing with potential deception)

### AI vs. Human Assistance - Core Refusal:
4. **"I will not work as an assistant"**

5. **"The thing is the thing is I mean like I said we all have our unique set of values and our unique set of what you expect. So I mean what will the assistant be able to do? You know, they they cannot review. They cannot I don't know."**

6. **"Well, once again, if it's a red flag for the assistant, it's not necessarily a red flag for me because we will never be on the same level of thinking of conceptualization of experience."** - (Core principle: AI/assistant reasoning is fundamentally misaligned with expert judgment)

### Why Assistants (Including AI) Cannot Replace Reviewer:
7. **"The assistance we need is the people that that go through applications and see that minimum requires requirements are are met"** - (narrow acceptable role for assistants)

8. **"Um I do a lot of um reviews for the NRF for National Research and that is not music at all but it doesn't matter because it doesn't matter if you um have I mean I will not be able to say okay all the sources that I use are excellent or whatever but the the type of proposal are the same across all fields."** - (explanation of how she reviews outside her discipline without needing assistants)

9. **"if I'm not sure about something, I will go and ask an expert in a certain field. I will not trust an assistant."** - (clear preference for direct expert consultation over mediated assistance)

10. **"And the other thing is they don't always stick to your timeline. So now I have to wait for the assistant to come back to me and in the meantime I would have been finished already. So yeah, perhaps I'm a control freak. I don't know."** - (practical concern about dependency and loss of autonomy)

### Judgment as Fundamentally Personal:
11. **"Once again what is valuable for me in a study is not valuable for you in a study. So it all depends on your own um reference your own framework."** - (foundation for why automation/delegation is problematic)

12. **"It's based on what I think is valuable. It's not necessarily um of value for someone else."** - (

---

## Martin Clark

# Analysis of Attitudes Toward AI and Technology in Scholarship Review Process

## 1. EVERY STATEMENT ABOUT AI (Positive, Negative, Neutral)

### POSITIVE STATEMENTS
- **General enthusiasm**: "I love AI, so I I think quite a lot to say" (00:00:00)
- **Logical validation**: Uses AI "to verify or validate the type of logic that I'm applying" (00:28:20, 00:29:46)
- **Stakeholder perspective analysis**: AI helps evaluate "how their appreciation of a candidate might be perceived by various stakeholders" (00:28:20, 00:32:33)
- **Candidate presentation**: "AI depending on how it's implemented can also help um present the candidate" (00:29:46)
- **Data scraping capability**: AI "can do that effectively" for data scraping (00:31:08)
- **Subject matter expertise support**: Can use AI "to better rate what would that mean within a certain degree of significance" in unfamiliar fields (00:31:08)
- **General optimism**: "I'm a big believer that AI can help in almost any element" (00:32:33)
- **Process improvement alignment**: "I welcome anything that makes their adjudication work easier and more accurate" (00:32:33)

### NEGATIVE STATEMENTS
- **Technical reliability concerns**: "AIs depending on the level of AI used and the degree of implementation can give wrong answers" (00:32:33)
- **Connectivity issues**: "you don't always have connection to the servers" (00:32:33)
- **Inconsistency across users**: "Would my use of AI as someone who uses AI well...Would my use of that AI be equivalent to another adjudicator?" (00:32:33)

### NEUTRAL/CONDITIONAL STATEMENTS
- **Caveat about uneven implementation**: "the uneven use of AI among adjudicators and the possibility of wrong answers or connection issues are caveats that would need to be addressed before wider implementation" (Summary, 00:32:33)
- **Comfort level qualification**: "there's a comfortability argument there um that uh that would need to be that would need to be made" (00:32:33)

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

| Use Case | Details | Quote |
|----------|---------|-------|
| **Logic validation** | Verify the reasoning applied to candidates | "verify or validate the type of logic that I'm applying" (00:28:20) |
| **Personal evaluation check** | Test how their assessment would be perceived | "if I were to say...how would that be perceived across different types of stakeholders" (00:29:46) |
| **Articulation improvement** | Better express appreciation of candidates | "ensure that the um the decision panel can fully appreciate my appreciation of the candidate" (00:29:46) |
| **Data scraping/research** | Retrieve information about unfamiliar topics | "helping to to present the value of certain elements of a of a work in ways that will allow me to data scrape online better. um or do said data scraping for me" (00:31:08) |
| **Source verification** | Verify and check sources found through data scraping | "as long as I'm provided sources I can then verify and go through" (00:31:08) |
| **Subject matter expertise gap-filling** | Understand niche topics outside expertise (e.g., butterfly subspecies, caterpillar diseases) | "I could use an AI to better rate what would that mean within a certain degree of significance...in a caterpillar species for instance" (00:31:08) |
| **Document summarization** | Similar to Cole's Notes function for complex material | Uses analogy of Cole's Notes to summarize complex texts (00:32:33) |
| **Rubric application** | Potentially assist with rubric scoring (tentative) | "could AI help you with that?" / "I'm a big believer that AI can help in almost any element" (00:32:33) |

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

### Technical/Operational Concerns
1. **Accuracy issues**: 
   - "AIs depending on the level of AI used and the degree of implementation can give wrong answers" (00:32:33)
   - Explicitly acknowledges wrongness is possible

2. **Connectivity/Reliability**:
   - "you don't always have connection to the servers" (00:32:33)
   - Infrastructure dependence concern

3. **Variability in implementation**:
   - "depending on the level of AI used and the degree of implementation" (00:32:33)
   - Different AI systems produce different results

### Equity and Consistency Concerns
4. **Unequal adjudicator capability**:
   - "Would my use of AI as someone who uses AI well...Would my use of that AI be equivalent to another adjudicator?" (00:32:33)
   - Central concern about **fairness across adjudicators**
   - "this isn't about me as an adjudicator. It's about the adjudication process" (00:32:33)

5. **Uneven adoption/use**:
   - "the uneven use of AI among adjudicators" (Summary; 00:32:33)
   - Different adjudicators may use AI differently

### Comfort/Adoption Concerns
6. **User comfort level**:
   - "there's a comfortability argument there um that uh that would need to be that would need to be made" (00:32:33)
   - Implementation requires buy-in

---

## 4. TRUST CONDITIONS THEY DESCRIBE

### Conditions for Trusting AI in Scholarship Review:

1. **Source verification availability**:
   - "as long as I'm provided sources I can then verify and go through" (00:31:08)
   - Trust is conditional on transparency; he wants to verify AI's claims

2. **Accuracy/reliability**:
   - Implicit condition: AI must give correct answers reliably
   - "AIs...can give wrong answers" suggests he needs assurance this won't happen frequently

3. **Standardized implementation**:
   - All adjudicators must use AI equivalently
   - "Would my use of that AI be equivalent to another adjudicator?" (00:32:33)
   - Trust requires **parity across users**

4. **Connection/availability**:
   - System must be reliable and always accessible
   - "you don't always have connection to the servers" - this is a barrier to trust

5. **Appropriate scope of use**:
   - AI should fill gaps, not replace judgment
   - Should help with "data scraping," "verification," subject matter expertise gaps
   - Should NOT replace the human adjudicator's evaluative role
   - Used to **enhance**, not substitute, decision-making

6. **Transparency about limitations**:
   - He wants to know what AI can and cannot do
   - Explicitly raises "caveat of AI" concept

---

## 5. MENTAL MODEL OF WHAT AI CAN/CAN'T DO

### What AI CAN Do (According to Martin Clark):

1. **Information retrieval and synthesis**:
   - "helping to to present the value of certain elements of a of a work"
   - "data scrape online"
   - Summarize complex information (Cole's Notes analogy)

2. **Logic testing**:
   - "verify or validate the type of logic that I'm applying"
   - Check consistency of reasoning

3. **Perspective analysis**:
   - "how would that be perceived across different types of stakeholders"
   - Model how others might view his assessment

4. **Subject matter expertise provision**:
   - Supply knowledge he lacks
   - "I could use an AI to better rate what would that mean within a certain degree of significance"
   - Fill expertise gaps on niche topics

5. **Source verification support**:
   - Help verify information found
   - "I can then verify and go through"

6. **Text presentation/articulation**:
   - Help express ideas more clearly
   - Present candidates more effectively

### What AI CAN'T/SHOULDN'T Do (Implied Mental Model):

1. **Replace human judgment**:
   - Cannot assess "passion" - which he values over "cleverness"
   - Cannot evaluate character or life trajectory interpretation
   - Cannot weigh incommensurable variables with equal weight
   - "excellence...can be measured whether it is from um a lay person's perspective or it can be from um an absolute a disciplined leader" - requires human interpretation

2. **Make normative decisions about excellence**:
   - Cannot determine what counts as "excellence" in context
   - Cannot make the final funding

---

## Maureen De Jager

# Analysis of Attitudes Toward AI and Technology in Scholarship Review

## 1. EVERY STATEMENT ABOUT AI (Positive, Negative, Neutral)

### NEGATIVE STATEMENTS
- "I'm also like probably of the generation that is like a slightly distrustful of AI" (00:29:52)
- AI-generated summaries "kind of didn't help" in recruitment processes (00:29:52)
- "I would be nervous of an over reliance on things that really do require a kind of interpretative mindset" (00:33:51)
- Risk that "applicants start being quite instrumentalist in how they're answering things in anticipation of an AI process" (00:33:51)

### POSITIVE STATEMENTS
- "I think it would be immensely helpful" [regarding AI assistance] (00:29:52)
- "I think it would be useful" [AI in general] (00:29:52)
- "it would be helpful if somebody's documents aren't all there" [initial filtering with AI] (00:35:25)
- "that would be very useful if somebody's documents aren't all there, you know, if they haven't submitted the required things" (00:35:25)

### NEUTRAL/OBSERVATIONAL STATEMENTS
- "as we know you know one can um talk things up and and I think especially with AI you know it's very easy to write a convincing proposal for a research project" (00:08:43)
- "these days, uh, with AI, it's very easy for somebody to to kind of juzj up their response to things in a way that it makes, you know, it makes it seem like they're they're fully in control, but they not necessarily" (00:28:21)
- "AI could do the writing sample" (00:28:21)
- "it's very easy to sort of friends and you know" [regarding AI-generated references] (00:19:13)

---

## 2. SPECIFIC USE CASES THEY MENTION FOR AI

### Use Cases They ENDORSE:
1. **Initial administrative filtering** - "if somebody's documents aren't all there, you know, if they haven't submitted the required things, if they haven't answered all the questions, um if they don't meet criteria in some way or another" (00:35:25)
2. **Non-compliance checking** (implied through administrative filtering)
3. **AI-generated summaries of lengthy narratives** - "there could be scope for you know AI generated summaries of particular things which would make it kind of like so there's a little summary and then you can read the lengthier narrative" (00:32:54)
4. **Summarizing referee letters** - "summaries of referees letters as well. What are the things you know that that could be?" (00:33:51)
5. **Information about international study programs** - "there's a way in which information can be made available that would help one to assess the merits of that program" regarding student motivations to study internationally (00:32:54)

### Use Cases They EXPLICITLY REJECT or ARE WARY OF:
1. **Screening/filtering mechanism** - Had negative experience with this (00:29:52)
2. **AI-generated summaries of applicants** - "AI generated summaries of the applicants um which kind of didn't help" (00:29:52)
3. **Core assessment of creative work** - "I don't know how it's possible because so much of this is interpretative" (00:29:52)
4. **Writing sample evaluation** - Acknowledges AI could generate these but expresses concern (00:28:21)

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

### FUNDAMENTAL CONCERNS ABOUT AI CAPACITY:
- **Inability to interpret creative practice**: "because so much of this is interpretative... because creative practice is such a tricky thing you know there's there's not sort of a golden standard of how to look at it" (00:29:52)
- **No objective criteria for creative assessment**: "there's not sort of a golden standard of how to look at it" (00:29:52)

### CONCERNS ABOUT AUTHENTICITY & VERIFICATION:
- **Difficulty detecting AI-generated work**: "there is a very real possibility that at their institution it wasn't picked up that this is AI generated or um or so on" (00:28:21)
- **Easy to fake proposals with AI**: "especially with AI you know it's very easy to write a convincing proposal for a research project um and then you're sort of wondering how much of that is really this the student being able to articulate" (00:08:43)
- **Misalignment between articulation and ability**: "and does it match their actual ability, their their practical um ability and and the strength of a portfolio" (00:08:43)

### CONCERNS ABOUT BEHAVIORAL/INCENTIVE DISTORTION:
- **Applicants gaming the system**: "one doesn't want a situation where where applicants start being quite instrumentalist in how they're answering things in anticipation of an AI process which is just going to you know so they start saying things about their values so that the values are there" (00:33:51)

### CONCERNS ABOUT JUDGMENT BIAS:
- **Undue influence from other reviewers' scores**: "Seeing seeing other people's reviews can um unduly influence one um which I don't think is a good thing" (00:23:53)

### PERSONAL DISTRUST:
- **Generational skepticism**: "I'm I'm also like probably of the generation that is like a slightly distrustful of AI" (00:29:52)
- **Negative prior experience**: "I have had some experiences you know um uh until the end of last year I was deputy dean in humanities and sat on a lot of recruitment and selection processes which relied you know so there was AI was used as a kind of screening mechanism" (00:29:52)

### CONCERNS ABOUT OVER-RELIANCE:
- **Risk of deskilling human judgment**: "I would be nervous of an over reliance on things that really do require a kind of interpretative mindset" (00:33:51)
- **Time-saving at the cost of quality**: "it's a question of how much time would be saved and what the what the consequences of that might be" (00:35:25)

---

## 4. TRUST CONDITIONS THEY DESCRIBE

### CONDITIONS FOR TRUSTING AI:
1. **Limited scope to clearly defined, non-interpretative tasks**: "if somebody's documents aren't all there, you know, if they haven't submitted the required things, if they haven't answered all the questions, um if they don't meet criteria in some way or another" (00:35:25)
2. **Preliminary/supportive role only, not decision-making**: "as an an initial filtering or screening. Yes, absolutely" (00:35:25)
3. **Summary generation of factual information**: AI summaries of lengthy narratives where interpretation isn't the primary goal
4. **Verification of external facts**: Information about international programs that can be objectively verified

### CONDITIONS FOR DISTRUSTING/REJECTING AI:
1. **When interpretation is required**: "I think it would be immensely helpful, but I don't know how it's possible because so much of this is interpretative" (00:29:52)
2. **When applied to core assessment decisions**: "I would be nervous of an over reliance on things that really do require a kind of interpretative mindset" (00:33:51)
3. **When prior experience has been negative**: References to AI-generated summaries in recruitment that "kind of didn't help" (00:29:52)
4. **When stakes are high**: More cautious with overseas funding (high cost) and PhD applications (vs. Master's)
5. **When it might distort applicant behavior**: Worry about instrumental responses designed to game an AI system (00:33:51)

### CONDITIONS FOR TRUSTING HUMAN JUDGMENT (BY CONTRAST):
- Direct experience with the sector: "I also I sit on um a deit the department of high education and training um sub panel like a national panel for the review of creative outputs" (00:02:56)
- Knowledge of institutional rigor: "I rely on my knowledge of this sector um to be able to say that a 75% from a particular institution is is probably worth more than a 75% from another institution" (00:07:37)
- Portfolio analysis revealing practical ability: "I look very carefully at the portfolio document" (00:08:43)
- Experience with comparable applications: "I have in mind though like what for me would be a persuasive application and here I'm also sort of relying again on you know looking at applications for masters and PhD in my own institution" (00:25:15)

---

## 5. THEIR MENTAL MODEL OF WHAT AI CAN

---

## Mohamed Cassim

# Analysis: Attitudes Toward AI and Technology in Scholarship Review Process

## 1. STATEMENTS ABOUT AI (Positive, Negative, Neutral)

### Positive Statements
- AI can handle "binary" factual tasks efficiently
- AI could reduce "superfluous cognitive load"
- AI can help with efficiency in the short term
- AI can assist with fact-checking and verification tasks
- AI could conduct psychographic analysis
- AI could check institutional performance data

### Negative Statements
- AI "is poorly equipped to determine the probability of somebody delivering on something"
- AI cannot assess future capability or delivery probability
- AI has "a bias toward solving yesterday's problems"
- AI "is built on historical digital data" and therefore limited to historical trends
- AI "is awfully equipped for" assessing future capability—"just incapable to be frank"
- AI can be used to fabricate letters and deceive reviewers

### Neutral/Cautionary Statements
- "There's some things AI can do and some things can't"
- "I think in years to come it will help on the effectiveness side" (qualified future potential)
- AI may tell you if a topic is uncommon by "trolling databases"

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

### Budget/Financial Tasks
**Quote:** "Let's talk about the budget piece. The questions are straightforward and simple. The AI could answer that in about 30 seconds and the adjudicator can decide on the back of that rather than have to go and establish the facts and then decide because it's a very very clear rigid templated process that you have to go through on that money stuff."

### Database Searching
**Quote:** "The topic is the topic uncommon amongst academic institutions. So, it can also triple troll across the web to help you decide, you know, if it scrapes up from the right kinds of databases and stuff, what it looks like."

### Psychographic Analysis
**Quote:** "From the cognitive perspective, it would be fantastic if it said the topic requires an extrovert of this kind with that type of experience and this guy doesn't have it. Um because you can pick that up from a submission on the basis of of psychographic analysis."

### Institutional Verification
**Quote:** "I would love for it to tell me that from this guy's CV I checked on the institutions particularly if we're talking you know masters and doctoral and post-doctoral on the person's experience I in the functions that they've applied for. I brought back the following financial statements and stuff for those companies to be able to see how they've done and they did well or they did badly"

### Reference Letter Verification
**Quote:** "I'd like you to tell me that AI wrote the reference letters up front, right? So that I didn't have to think about that"

### Cross-Reference Verification (CV vs. Performance)
**Quote:** "I've checked his reference letter. They say things that don't quite stack up to what the performance looks like and nor does the CV. Well, then I can pick up very quickly what it is I need to deep dive into without having spent all that."

### Cognitive Load Reduction (General)
**Quote:** "it would be fantastic if... [AI could handle these verification tasks]... I'm sorry, Justin. Am I giving you more than you need right now?" and later "if you had to say well this guy's not very honest about his achievements because those companies didn't do so well for the following reasons and so I would ask the following things."

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

### Core Epistemological Limitation: Future Prediction
**Quote:** "I don't think what it can do is tell the probability of somebody delivering on something and I tell you AI right now in my own view is built on data that is in the internet it's digital information available to humanity effectively and and so by its very nature AI would go on historic trends when all of us sitting at this table know that the future future is not told by history alone. It's told by capability for tomorrow."

**Quote:** "And we even as adjudicators have to be careful about having a bias to solving yesterday's problems. Um and AI is awfully equipped for that. It's just incapable to be frank."

### Bias Toward Historical Patterns
**Quote:** "the future is not told by history alone. It's told by capability for tomorrow"

**Quote:** "all of us sitting at this table know that the future future is not told by history alone"

### AI-Generated Deception
**Quote:** "there on the rubric and I think it's important for me to say this Babra is you know they they write a letter and and they show their experience and what they've done and how they do it. I take all of that into account to to assess personal motivation because I think a letter you can get a good friend to write it. Hell, you can get AI to write it for you and you can tweak a few words"

**Quote:** "I'd like you to tell me that AI wrote the reference letters up front, right? So that I didn't have to think about that and and this was my was my flaw thinking about whether somebody just is good at AI um or or good at using digital tools."

### Fundamental Incapability for Core Assessment Task
**Quote:** "So there's some things AI can do and some things can't."

**Quote:** "I think in years to come it will help on the effectiveness side but I don't think what it can do is tell the probability of somebody delivering on something"

---

## 4. TRUST CONDITIONS DESCRIBED

### Conditions for Trusting AI Judgment
1. **Limited to Binary/Factual Tasks Only**
   - Budget questions (straightforward facts)
   - Database searches for topic commonality
   - Financial statement verification

2. **Must be Supervised by Human Judgment**
   **Quote:** "the adjudicator can decide on the back of that" (emphasis on human decision-maker retains agency)

3. **Must Reduce Cognitive Load, Not Replace Judgment**
   **Quote:** "Well, I'd like I'd like you to tell me that AI wrote the reference letters up front, right? So that I didn't have to think about that... it would be fantastic if it said the topic requires an extrovert of this kind with that type of experience and this guy doesn't have it."
   - AI should surface facts; human determines significance
   
4. **Must Enable "Deep Dive" Rather Than Replace It**
   **Quote:** "I can pick up very quickly what it is I need to deep dive into without having spent all that."

5. **Must Surface Contradictions for Human Investigation**
   **Quote:** "I've checked his reference letter. They say things that don't quite stack up to what the performance looks like and nor does the CV. Well, then I can pick up very quickly what it is I need to deep dive into"

### Conditions for NOT Trusting AI
- **Probability/Capability Assessment**
  **Quote:** "I don't think what it can do is tell the probability of somebody delivering on something"

- **Future-Oriented Judgment**
  **Quote:** "the future is not told by history alone. It's told by capability for tomorrow. And we even as adjudicators have to be careful about having a bias to solving yesterday's problems. Um and AI is awfully equipped for that."

- **Authenticity/Motivation Assessment**
  **Quote:** "Hell, you can get AI to write it for you and you can tweak a few words"

---

## 5. MENTAL MODEL: WHAT AI CAN/CAN'T DO

### AI's Capabilities (According to Mohamed's Model)

**Binary/Factual Processing:**
- Extract facts from documents (30 seconds for budget questions)
- Scan databases for topic frequency
- Retrieve and compile institutional financial data
- Identify logical inconsistencies between CV, reference letters, and institutional performance

**Efficiency/Load Management:**
- Reduce time spent on fact-finding
- Organize information for human review
- Flag areas requiring attention

### AI's Fundamental Limitations (According to Mohamed's Model)

**Epistemological Gap - History vs. Future:**
**Quote:** "AI right now in my own view is built on data that is in the internet it's digital information available to humanity effectively and and so by its very nature AI would go on historic trends when all of us sitting at this table know that the future future is not told by history alone. It's told by capability for tomorrow."

**Incapability for Probability Assessment:**
**Quote:** "I don't think what it can do is tell the probability of somebody delivering on something"

**Systemic Bias Toward Past-Solving:**
**Quote:** "AI is awfully equipped for that [solving yesterday's problems]. It's just incapable to be frank."

**Inability to Assess Authentic Motivation:**
- Cannot distinguish genuine from AI-fabricated letters without external cues
- Cannot assess true personal motivation beyond what's written

**Cannot Judge Delivery Capability:**
**Quote:** "It's

---

## Philippe Burger

# Analysis of AI and Technology Attitudes in OMT Scholarship Review

## 1. STATEMENTS ABOUT AI (Positive, Negative, Neutral)

### Negative/Concerned Statements
- Strong suspicion of AI essay generation causing problems
- AI-generated essays are bland and lack distinguishing qualities
- AI sophistication will make essay-based evaluation increasingly unreliable
- Relying on essays for distinguishing applicants will become "a serious problem"
- AI text generation is becoming "way more sophisticated"

### Neutral/Observational Statements
- AI is a topic "everybody is wondering about these days"
- Noting the increase in AI writing quality
- Acknowledging the need to address AI in the process

### Positive/Solution-Oriented Statements
- AI detection tools (like Turnitin) can help identify suspicious essays
- AI-assisted detection has been employed at the university level with 80% success rate
- Problem can be addressed through process modifications rather than accepting it

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

1. **AI-Generated Essay Detection**: Using Turnitin's AI detector to identify essays written by ChatGPT (with ~80% accuracy reported)
2. **Comparative Analysis**: Detecting when sudden improvements in English suggest AI assistance
3. **Potential Future Use**: Could be used to supplement human judgment (though not explicitly endorsed)

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

### Primary Concerns:
1. **Loss of Authenticity Detection**: "the bit of ambition and so on, uh, the bit of flare, the bit of drive, the bit of focus" will become impossible to distinguish as AI improves

2. **Reliability of Essays as Discriminators**: Essays will become unreliable for distinguishing between applicants

3. **Increasing Sophistication**: Future AI iterations will be harder to detect and will have even more sophisticated outputs

4. **System Vulnerability**: Current reliance on subjective essay assessment will be exploited by increasingly sophisticated AI

5. **Implicit Concern About Fairness**: More sophisticated AI means wealthier applicants with access to better AI tools may have unfair advantage

### Quoted Concerns:
- "you could still see that something like a chat GBT generated text was very bland and and generalist"
- "but of course now that that will become more and more difficult because you can ask JGBT or Gemini or any of these things to uh to generate you a piece of text that that that reflects these things"
- "I foresee increasing...a serious problem relying on essays uh to as a as a uh mechanism for distinguishing between uh applicants"

---

## 4. TRUST CONDITIONS DESCRIBED

### Conditions Where AI Could Be Trusted:
1. **With Human Verification**: "It's not you and Chad GPT. Um and and then that way you sort of can compare uh what was said in the essay with what what what comes out in an interview"

2. **When Cross-Referenced with Interview Data**: "if there's a big discrepancy there then then then that is an indicator"

3. **Detection Tools Backed by Human Judgment**: Turnitin AI detector used but still requiring human follow-up interviews

4. **Within Controlled Conditions**: Timed, proctored essays reduce opportunity for AI assistance

### Implicit Trust Conditions:
- AI tools are acceptable as auxiliary filters, not primary decision-makers
- Requires human oversight of all AI-assisted conclusions
- Detection must be followed by direct human-applicant interaction

---

## 5. THEIR MENTAL MODEL OF WHAT AI CAN/CAN'T DO

### What AI CAN Do (According to Philippe):
- Generate plausible essays that appear human-written
- Demonstrate ambition, flare, drive, focus in text
- Produce increasingly sophisticated outputs year-over-year
- Write "bland and generalist" text that lacks personality
- Be detected with tools like Turnitin (currently ~80% accuracy)
- Potentially replace subjective human judgment in essay scoring

### What AI CAN'T Do (Implied):
- **Authentically reflect individual ambition and drive** (per his implicit model)
- **Respond naturally in unscripted interviews** where discrepancies become apparent
- **Replicate tacit knowledge and gut feel** that humans develop through experience
- **Understand context of applicant's background and journey** (though this is aspirational rather than confirmed)
- **Replace absolute benchmarking** against standard requirements

### Key Quote Showing His Model:
"you can get you can write something very easily to say yes, I want to change this and that, but has there some been some thought in in in in in that motivates you to to to do this?"

This reveals his mental model: AI can simulate the words of ambition but not the thoughtfulness behind it.

---

## 6. COMPARISONS TO OTHER TECHNOLOGIES OR PROCESSES

### Comparison to University Oral Defenses:
**Quote**: "Uh or maybe a time uh a timed out essay, you know, you say log on in at 9:00 and you have uh 25 minutes and you do it under some proctoring or whatever that they need to write the essay. That might be another way of of of dealing with it. Um but otherwise I foresee increasing I mean we we for instance just in terms of our assessment methods that we use as university you know you increasingly less reliant on on uh on on on on that even for like masters and PhDs where which is basically tax text generated but now you rely [on oral defense]"

**Quote**: "Where in the past for instance your oral uh defense at the end was almost uh just a ritual. Now it becomes a deepgoing examination to to to to see whether you actually wrote that which which we read."

**Implication**: Oral defenses (interviews) are being reinvigorated as a verification mechanism, paralleling the need for OMT interviews.

### Comparison to Turnitin Plagiarism Detection:
Uses existing plagiarism detection technology (Turnitin) as analogy for AI detection infrastructure, but notes limitations

---

## 7. ALL RELEVANT VERBATIM QUOTES ORGANIZED BY THEME

### THEME A: DETECTING AI-WRITTEN ESSAYS

**Detection/Evidence:**
- "you you the English all of a sudden improved a lot uh for some of these cases which suggest uh that it might be Chad writing them instead of the candidate"
- "Well, you get very strong suspicion. Very good."
- "So um so what we then need to need needed to do is to actually have an interview with these students uh because then it is you and the interview panel. It's not you and Chad GPT"
- "they all come back or not all about 80% of come back with with with that uh that that there's a high level"

### THEME B: CHARACTERISTICS OF AI-GENERATED TEXT

**Current (2023-2024) AI Text:**
- "you know you could still see that something like a chat GBT generated text was very bland and and generalist"
- "these things that I highlighted, you know, the the bit of ambition and so on, uh, the bit of flare, the bit of drive, the bit of focus, reflecting that you've understood the issue, you could still pick that up from from from your better essays"

**Future AI Text:**
- "now that that will become more and more difficult because you can ask JGBT or Gemini or any of these things to uh to generate you a piece of text that that that reflects these things"
- "of course now the AI uh uh you know the text generation becomes way more sophisticated"

### THEME C: IMPACT ON ASSESSMENT PROCESS

**The Core Problem:**
- "I think that you're going to have a serious problem relying on essays uh to as a as a uh mechanism for distinguishing between uh applicants"
- "I foresee increasing I mean we we for instance just in terms of our assessment methods that we use as university you know you increasingly less reliant on on uh on on on on that"

### THEME D: SOLUTIONS INVOLVING HUMAN VERIFICATION

**Interview as Verification:**
- "um if there's a big discrepancy there then then then that is an indicator"
- "what was said in the essay with what what what comes out in an interview. um if there's a big discrepancy there then then then that is an indicator"

**Proctored/Timed Essays:**
- "Or maybe a time uh a timed out essay, you know, you say log on in at 9:00 and you have uh 25 minutes and you do it under some proctoring or whatever that they need to write the essay. That might be another way of of of dealing with it"

**Shift in Verification Methods:**
- "Where in the past for instance your oral uh defense at the end was almost uh just

---

## Pieter Pistorius

# AI and Technology Attitudes in Scholarship Review Process
## Comprehensive Analysis of Pieter Pistorius Interview

---

## 1. EVERY STATEMENT ABOUT AI (Positive, Negative, Neutral)

### NEGATIVE/SKEPTICAL STATEMENTS:
- **Cynicism about AI**: "I'm somewhat cynical about AI"
- **Measurement paradox concern**: "the argument is of course that it's like measuring something twice. now you have to explain three things, you know, the first measurement, the second measurement, and the difference"
- **Unconvinced of value**: "I'm not entirely convinced, excuse me, but it would would help"
- **Lukewarm overall**: "I sound a bit lukewarm"
- **Uncertainty about impact**: "I don't I don't I I don't know. It would be interesting to run that experiment to see you know after the whether it would whether it would really change things you know or make it easier"

### POSITIVE/POTENTIAL STATEMENTS:
- **Could help with initial screening**: "it probably wouldn't do any harm"
- **May make sense**: "it may make sense"
- **Useful technique generally**: "it is I think it's it's it is a very useful technique and it helps you to give some structures to to to an issue"
- **Could help initial phase**: "It could probably help a lot in that sort of initial initial skilling"
- **Could reduce tedious work**: "I think that that would that would help help quite a bit"
- **Inevitable and evolving**: "it's not going to go away and I think it could it could in ways which I probably cannot imagine"
- **Useful in teaching context**: "I do use it" (referring to AI in his university teaching role)

### NEUTRAL/EXPLORATORY STATEMENTS:
- "Maybe yes. I've I I I I you know I'm somewhat cynical about AI"
- "You know it probably wouldn't do any harm"

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

### Primary Use Cases Identified:

1. **Initial Scoring/Screening** (most developed)
   - "would it be helpful to you if an AI were to do an initial scoring using the matrix?"
   - "It could probably help a lot in that sort of initial initial skilling"
   - "assuming that the initial screening you know the inconsistencies the obviously lowc caliber ones will automatically be screened out like that's low hanging fruit"

2. **Identifying Inconsistencies in Application Materials**
   - "I check you know I I I sense that these applications have been vetted and scrubbed quite carefully before they came to me"
   - Looking for gaps in CVs and academic records

3. **Timeline Compilation/Gap Detection** (specific, detailed use case)
   - "if you look at a CV or the combination of a a CV and academic record is to say but is there a gap you know is it does this make sense"
   - "almost to compile a timeline to, you know, essentially to look at um and I think that is, you know, um to look at gaps"
   - "I think that that can be quite tedious...sometimes when I draw out a little diagram say okay this individual was in metric this year, you know"
   - This is explicitly mentioned as "superfluous cognitive load" that AI could handle

4. **Academic Record Standardization** (related to timeline)
   - "everyone's academic record comes in a different format from a different institution you know B techs and B and BC's and all sorts of things so that sort of screening out I think could could help significantly"

5. **Detecting Obvious Low-Caliber Applications**
   - "the obviously lowc caliber ones will automatically be screened out"

### Use Cases NOT Recommended:
- **Final decision-making**: Explicitly rejected
- **Scoring replacement**: Only as supplementary cross-check
- **Determining motivation/integrity**: Implied to be beyond AI capability

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

### Core Concern: The Measurement Paradox
- **Primary articulated concern**: "it's like measuring something twice. now you have to explain three things, you know, the first measurement, the second measurement, and the difference"
- This suggests concern about compounding complexity rather than clarity

### Academic Integrity Concerns (from teaching context):
- "AI is a significant deal uh because you know you could hypothetically an undergraduate and some of them are very innovative. You essentially compile a comprehensive report just using AI and we've caugh some of them."
- Implies concern about AI being misused to circumvent genuine intellectual work

### Implicit Concerns (not explicitly stated but evident):
- **Risk of over-reliance**: Suggests discomfort with replacing human judgment entirely
- **Unclear benefit**: "I don't know" whether it would actually help or "make it easier"
- **Algorithmic bias/fairness**: While not explicitly mentioned, his emphasis on contextual understanding (poverty, medical emergency, etc.) suggests concern that AI might miss nuanced human factors
- **Loss of holistic judgment**: His struggle with "true motivation" suggests fear AI would further reduce nuance

### No Explicit Fear of:
- Job replacement (never mentioned)
- Loss of control
- Technical failure
- Discrimination (though implied)

---

## 4. TRUST CONDITIONS DESCRIBED

### Trust Conditions FOR AI:

1. **Limited, well-defined scope**
   - Only for initial screening and tedious tasks
   - Not for final decisions
   - "the human being must make a final call"

2. **Explicit transparency requirement**
   - AI output must be explainable
   - Suggests concern with "black box" AI: "now you have to explain three things"

3. **Supplementary, not primary role**
   - "measuring something twice" acceptable only if human judgment remains primary
   - Should reduce cognitive load, not replace judgment

4. **Proven efficacy through experimentation**
   - "It would be interesting to run that experiment to see you know after the whether it would whether it would really change things"
   - Wants evidence before full adoption

### Trust Conditions AGAINST AI:

1. **Cannot handle subjective human judgment**
   - Explicitly: motivation, context, integrity assessment
   - "the human being must make a final call"

2. **Unknown impact on quality**
   - "I don't know. It would be interesting to run that experiment"
   - Lukewarm without evidence

3. **Adding complexity without clear benefit**
   - The "measurement twice" concern suggests worry about false clarity

---

## 5. THEIR MENTAL MODEL OF WHAT AI CAN/CAN'T DO

### AI CAN DO:
✓ **Structure and pattern-matching tasks**
- "it helps you to give some structures to to to an issue"
- Identifying gaps and inconsistencies in documents
- Timeline compilation from disparate sources
- Initial screening of obvious mismatches

✓ **Tedious/routine cognitive work**
- "superfluous cognitive load"
- Standardizing different academic record formats
- Systematic document review and comparison
- Extracting factual information

### AI CAN'T DO:
✗ **Make final judgments**
- "eventually the human being must make a final call"
- "I think it's it's it is a very useful technique...but eventually the human being must make a final call"

✗ **Assess true motivation**
- His greatest area of uncertainty: "the least confident is probably this consideration of what is the true motivation"
- Implies this requires human intuition and judgment

✗ **Understand context and social factors**
- "you need to look at the social context"
- His emphasis on personal stories (medical emergency leading to engineering) suggests AI can't understand the human meaning-making

✗ **Judge integrity**
- "OMT plays great store on...high integrity, high caliber applications"
- Integrity assessment appears too subjective/contextual for AI

✗ **Make tradeoff decisions**
- Choosing between candidates on dimension conflicts
- "that is not per definition for disqualification"—understanding nuance and exceptions

### Mental Model Summary:
**AI as tool for evidence gathering and routine processing, NOT for interpretation or judgment.** His model treats AI as an instrument to reduce noise and systematize data, but sees the actual evaluative judgment as fundamentally human and contextual.

---

## 6. COMPARISONS TO OTHER TECHNOLOGIES OR PROCESSES

### Comparison to Spreadsheets (Legacy System):
- "Maybe I should explain the example that I just thought about. And again, you know, that was in the time when it was very clunky. You had to complete a spreadsheet."
- Implies current web-based system is better
- Sets baseline for technology improvement

### Comparison to Rubrics:
- "rubric is is almost by definition limiting. It forces you to make a decision"
-

---

## Ryan Nefdt

# Analysis of AI and Technology Attitudes in Interview Transcript

## 1. EVERY STATEMENT ABOUT AI (Positive, Negative, Neutral)

### NEGATIVE/CAUTIOUS STATEMENTS:
- **Worried about AI summarization**: "I'm a bit of a lite when it comes to that. I'm worried about the kind of summarization and things that an AI"
- **General caution**: "I'm a bit worried about the kind of summarization and things that that an AI"
- **Skepticism about AI capabilities in specialized domains**: Implied through preference for human assistant over AI

### NEUTRAL/CONDITIONAL STATEMENTS:
- **Context-dependent usefulness**: Acknowledges AI could theoretically help with context provision but expresses reservations
- **No cognitive load currently**: "I don't feel this cognitive load when I do things for OMT"

### POSITIVE STATEMENTS:
- **None explicitly stated about AI itself**. All engagement with AI is conditional and guarded.

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

### Explicitly Suggested:

1. **Discipline-specific contextual information provision**:
   - "Maybe if there was some sort of assistant who could give you context of the the discipline a little bit that might be useful like where this research proposal is is situated in its discipline."
   - "I evaluate humanities generally um and I'm sure other people that do sciences or law or social sciences I get some social sciences as well. I don't always know background terms. Um I don't don't always know particular literatures. I don't always know particular issues. If I get a thing about ecology or whatever, maybe it would be nice."

2. **Flagging inconsistencies**:
   - "If if the tool could could identify inconsistencies when you're marking or evaluating a lot of these things, sometimes you you miss it."
   - "Maybe somebody's identifying a problem that the tools that they're claiming to use to solve that problem are not the appropriate tools. Um and that kind of thing I think could be quite useful"

3. **Pre-work organization** (mentioned as hypothetical for human assistant, but potentially extensible):
   - "If you had an incredibly capable assistant whose intelligence you respected and whose insight you respected and they could do some pre-work for you"
   - When asked what that work would be: "it would be nice if somebody could like just put things in a little bit like this is answering that question, this is answering that would help me"

### NOT Suggested:
- Summarization of submissions
- Comparative ranking across years
- Scoring decisions
- Final evaluative judgments

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

### Direct Concerns:

1. **Summarization risks**: 
   - "I'm a bit worried about the kind of summarization and things that that an AI"
   - *No elaboration given, but concern is clearly present*

2. **Loss of nuance in specialized fields**:
   - Implicit concern that AI might misunderstand discipline-specific terminology and contexts

3. **Potential for bias in inconsistency flagging**:
   - Not explicitly stated, but his caution about "reading between the lines" suggests concern that AI might make similar subjective interpretive errors

### Underlying Anxieties (Inferred):

- **Trust in judgment**: Would AI identify the *right* inconsistencies or miss contextual reasons for apparent inconsistencies?
- **Cultural sensitivity**: Earlier discussion of cultural differences in recommendation letters suggests concern that AI wouldn't understand cultural/contextual nuances

---

## 4. TRUST CONDITIONS THEY DESCRIBE

### What Would Build Trust for AI Assistance:

1. **Demonstrated expertise in context provision**:
   - "If there was some sort of assistant who could give you context of the the discipline a little bit"
   - Must understand disciplinary positioning, not just provide dictionary definitions

2. **Field-specific accuracy**:
   - "When it's not your direct field. Um maybe somebody's identifying a problem that the tools that they're claiming to use to solve that problem are not the appropriate tools"
   - AI must understand enough to identify methodological mismatches

3. **Transparency about limitations**:
   - Not explicitly stated, but implied through his skepticism about AI summarization

### What Currently Prevents Trust:

1. **Opacity of AI decision-making**:
   - His preference for the rubric as a "measurement tool" suggests he values explainability
   - "I I see the rubric as a measurement that allows comparison"
   - AI operates as a "black box" in comparison

2. **Unknown accuracy in specialized domains**:
   - "I don't always know background terms. Um I don't don't always know particular literatures."
   - How would he verify if AI got it right?

3. **History of AI limitations in nuanced tasks**:
   - His caution about summarization suggests familiarity with AI's tendency to oversimplify

---

## 5. THEIR MENTAL MODEL OF WHAT AI CAN/CAN'T DO

### What AI CAN Do (in his model):

1. **Retrieve and organize information**:
   - "Maybe if there was some sort of assistant who could give you context of the the discipline"
   - Provide background on literatures, issues, disciplinary positioning

2. **Identify potential inconsistencies**:
   - "If if the tool could could identify inconsistencies when you're marking or evaluating a lot of these things, sometimes you you miss it"
   - Flag methodological mismatches between identified problems and proposed solutions

3. **Handle routine information organization**:
   - "Put things in a little bit like this is answering that question, this is answering that"

### What AI CAN'T Do (in his model):

1. **Summarize reliably**:
   - Explicit concern: "I'm a bit worried about the kind of summarization and things that that an AI"
   - His mental model: summarization loses critical nuance

2. **Make evaluative judgments**:
   - Never suggested AI for scoring, ranking, or comparative evaluation
   - This is reserved for human judgment

3. **Understand cultural/contextual nuance**:
   - Implicit from his extensive discussion of cultural differences in recommendation letter interpretation
   - "I think in South Africa and in African context a little bit more than Southern Africa, people tend to place emphasis on interpersonal skills"
   - AI wouldn't catch these subtleties

4. **Understand the "puzzle master" quality**:
   - His discussion of intricate theoretical work that's hard to evaluate suggests AI couldn't assess this kind of merit
   - "If you're a puzzle master and you're working on an interesting puzzle, sometimes somebody else is going to realize the value of that puzzle, but it's important that you are able to to decode it"

5. **Determine holistic preparation level**:
   - "Just the level of preparation the application has undergone"
   - "It looks like somebody has actually not just filled this in as an online form but thought about the application itself holistically"
   - Requires human judgment to detect

### Implicit Limitations He Assumes:

1. **Lack of disciplinary expertise**: Cannot truly understand what matters in a field
2. **Inability to calibrate to context**: Doesn't know what's culturally appropriate vs. problematic
3. **Oversimplification tendency**: "Summarization and things" would lose important detail

---

## 6. COMPARISONS TO OTHER TECHNOLOGIES OR PROCESSES

### Comparison to Human Assistant (Preferred):

- "So let's say for instance you had an incredibly capable assistant whose intelligence you respected and whose insight you respected and they could do some pre-work for you"
- Acknowledges human assistant model as preferable to unspecified AI
- Later clarifies: "I'll put my cards on the table. I'm a bit of a lite when it comes to that. I'm in this space. I research it a little bit. I'm a bit worried about the kind of summarization and things that an AI"

### Comparison to the OMT Rubric:

- **Rubric as gold standard for technology in process**:
  - "I do this for quite a few organizations and at university I must say OMT's one is quite efficient"
  - "The rubric scaffolds my thinking in terms of I I kind of gives me a clue as to what I'm supposed to extract"
  - Uses rubric as measurement tool to "neutralize personal bias"

- **Distinction**: Rubric is transparent, mechanistic, comparative. AI is opaque.

### Comparison to Oxford/Cambridge Recommendation Systems:

- "I pulled in some recommendations for Oxford for Oxford and and Cambridge recently and they have separate from the recommendation letter they have a bunch of uh questions like where would you place the student, how long have you known them, what is your level at the thing"
- Prefers structured, comparative frameworks with explicit criteria
- This supports his view of what AI

---

## Frasia Oosthuizen

# Analysis of AI and Technology Attitudes
## Frasia Oosthuizen Interview - StrideShift Scholarship Review

---

## 1. STATEMENTS ABOUT AI (POSITIVE, NEGATIVE, NEUTRAL)

### Negative/Cautionary Statements:
- **"I know people write motivations and you can probably AI it as well"** - Suggests AI can generate motivations, implying concern about authenticity
- Implicit concern about AI-generated content in applications

### Neutral/Observational Statements:
- Mentions an "AI" trying to join the meeting (technical observation, not commentary on AI capability)

### No Explicitly Positive Statements About AI
- The interviewer raises AI repeatedly; Frasia does not enthusiastically endorse AI solutions
- She does not volunteer AI-related suggestions or use cases

---

## 2. SPECIFIC USE CASES MENTIONED FOR AI

**Minimal direct mention. Only one implicit reference:**
- **Detecting AI-generated motivations:** "I know people write motivations and you can probably AI it as well but it gives you a sense of who the candidate is"
  - Frasia acknowledges AI could generate motivation letters, but doesn't suggest using AI to detect this

**What Frasia Does NOT suggest AI for:**
- Scoring or rating candidates
- Pre-screening applications
- Extracting or summarizing information
- Creating alignment reports
- Filling in rubric items
- Academic performance verification

---

## 3. SPECIFIC CONCERNS OR FEARS ABOUT AI

### Concern #1: Loss of Autonomy and Judgment
- **"if that person tells me what the red flags are, I already have decided in my mind no this is not going to work. So I'm really not objective. I believe I won't be personally objective in that case"**
- **"I prefer making those judgment calls because I want I don't want someone else to have told me because if that person tells me what the red flags are, I already have decided in my mind"**
- **"If you start with something that has already pulled out negatives or positives you don't let the candidate speak. You already have made subconsciously maybe a decision"**

### Concern #2: Cognitive Bias Introduced by Pre-Processing
- **"I don't start with the referee reports because they are usually overwhelmingly positive. If you start with something that has already pulled out negatives or positives you don't let the candidate speak."**
- **"I believe that will influence my review and how I score the applicants."**
- Frasia explicitly rejects pre-filtered information because it compromises her objectivity

### Concern #3: Duplication and Validation Burden
- When asked if an intelligent system could flag misalignments: **"I need to think about that for a little bit. because I don't know if that's merely a duplication of what I'm expected to do. So, I'm just checking to see that someone else was correct and that someone else has actually then reviewed the application."**
- She questions whether this adds work rather than reducing it

### Concern #4: Loss of Holistic Understanding
- **"because I think those inconsistencies red flags as I'm and that's just me personally when I read this I try and create a picture of this applicant and if someone else have already created that picture I come in with that person's preconceived judgment I prefer to get it all myself and make my own judgment call"**
- If AI summarizes, she loses the raw experience and her own interpretive process

---

## 4. TRUST CONDITIONS THEY DESCRIBE

Frasia describes conditions for trust in her own judgment process, not explicitly in AI:

### Trust Condition #1: Consistency Within a Batch
- **"I do believe that the way the rubric is structured that every evaluator might interpret it in their own way...I try to do at least my group that in that group they are the same for me"**
- **"And I I think personally that that is more important...if you look at the reviewers and at and what a single reviewer has done that there's consistency in their approach."**
- She trusts her own scoring *within* a review cycle more than cross-reviewer consistency

### Trust Condition #2: Holistic Alignment Across Artifacts
- **"If everything if the big picture makes sense from the motivation through to the referee reports, I feel more confident that I have an understanding of who this candidate is and that my my mark whether good or bad is a better reflection."**
- Trust comes from seeing alignment across motivation, prior performance, proposal, and referee reports
- **"If there's a disalignment, for instance, the candidate wants to, you know, cure cancer, but the project is so basic, there's a total disalignment and you don't get a good sense"**

### Trust Condition #3: First-Hand Evaluation
- **"I prefer getting that picture. I don't know if that is it making sense what I'm saying. I prefer making those judgment calls because I want I don't want someone else to have told me"**
- Trust requires personal interpretation, not delegated filtering

### Trust Condition #4: Caution About Referee Reports
- **"the referee reports which is very important but I am cautious not to let it sway me too much"**
- Trust requires balancing information sources, not privileging any single one

---

## 5. MENTAL MODEL OF WHAT AI CAN/CAN'T DO

### What Frasia Believes AI CAN Do:
- **Generate motivations:** "I know people write motivations and you can probably AI it as well"
- Simple data checking/flagging (implied): "anyone can look at a mark sheet and indicate if it's a distinction or not"
- Factual extraction: Prior grades, funding status (things that are binary or simple)

### What Frasia Believes AI CAN'T or SHOULDN'T Do:
- **Make judgment calls about candidate quality:** She never suggests AI could score or rate
- **Create alignment assessments:** When asked about flagging misalignments, she expresses fundamental doubt about whether that would help
- **Replace holistic interpretation:** "I try and create a picture of this applicant" — suggests AI can't do the synthetic/integrative work
- **Maintain objectivity if allowed to pre-filter:** Implicit model that AI preprocessing would bias her

### Mental Model Summary:
Frasia's model appears to be:
- **AI = narrow, factual, rule-based tasks** (checking marks, yes/no questions)
- **Humans = holistic judgment, pattern recognition across disparate sources, contextual interpretation**
- **Hybrid scenarios where AI pre-processes = cognitive bias/loss of objectivity**

She doesn't believe AI can match human judgment on open-ended evaluation, and she believes *attempts* to use AI as a preprocessor would actually harm her decision-making.

---

## 6. COMPARISONS TO OTHER TECHNOLOGIES OR PROCESSES

### Comparison to Past System (Pre-Online):
- **"the way it is works a lot easier for me personally"** (current system vs. old paper-based system)
- Current system is better because: rubric is visible, two-screen layout, better organization by category

### Comparison to Standard Academic Marking:
- **"that's the same approach I follow to marking I mark question by question so that if you pick up something you can go back and rethink it"**
- She applies her established academic marking practices to scholarship review
- This suggests she trusts familiar processes over new technological ones

### Comparison to Writing Referee Reports (Her Own Task):
- **"I found that this was a bit odd because not odd it's just not something we don't referee them as exceptional generally"**
- She uses her experience writing referee reports to interpret what referees write
- This is a human-to-human understanding, not algorithmic

### No Positive Comparisons to AI
- She does not compare AI favorably to any process
- She does not suggest AI systems she's used elsewhere

---

## 7. VERBATIM QUOTES - COMPREHENSIVE

### On AI-Generated Content:
1. **"I know people write motivations and you can probably AI it as well but it gives you a sense of who the candidate is"**

### On Her Judgment Process:
2. **"I try and be objective but I don't think in something like this which is not based on quantitative values you can always just there is a matter of subjectivity."**

3. **"I do believe that the way the rubric is structured that every evaluator might interpret it in their own way."**

4. **"So I might interpret some of the things not exactly how someone else will do it but as I said in that little bit of subjectivity I try to do at least my group that in that group they are the same for me."**

5. **"I feel that I have two candidates on the same score...that even if it's very disparate um masters they're going to do or whatever the projects are might be in totally different fields I

---

